{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vlcWrCZGiPRM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.datasets import fashion_mnist\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OLGP4dlAQjyZ",
    "outputId": "5e331d30-d8a9-46fb-f77a-3cf210f38da3"
   },
   "outputs": [],
   "source": [
    "!pip install cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TfO2B6v6BVWj"
   },
   "outputs": [],
   "source": [
    "class PreProc:\n",
    "    def __init__(self):\n",
    "        (self.trainx,self.trainy),(self.testx, self.testy) = fashion_mnist.load_data()\n",
    "    def visualize(self,n):\n",
    "        for i in range(n):\n",
    "            plt.subplot(330+1+i) # ask someone why??\n",
    "            plt.imshow(self.trainx[i], cmap = plt.get_cmap('gray'))\n",
    "        plt.show()\n",
    "    def flatten(self):\n",
    "        trainx_flattened = self.trainx\n",
    "        testx_flattened = self.testx\n",
    "        trainx_flattened.shape = (60000,784)\n",
    "        testx_flattened.shape = (10000,784)\n",
    "        return trainx_flattened,testx_flattened\n",
    "    def getLabels(self):\n",
    "        return self.trainy, self.testy\n",
    "    def getInputSize(self):\n",
    "        return len(self.trainx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4HhzRi0xhOLc"
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "7BwoVy0bPFA0"
   },
   "outputs": [],
   "source": [
    "class Functions:\n",
    "    @staticmethod\n",
    "    def sigmoid(input):\n",
    "        input = np.clip(input, -100,100)\n",
    "        return  1.0/(1.0+np.exp(-input))\n",
    "    \n",
    "    @staticmethod\n",
    "    def reLU(input):\n",
    "        input = np.clip(input, -1e10,1e10)\n",
    "        return np.maximum(0,input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def tanh(input):\n",
    "        return np.tanh(input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def identity(input):\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(input):\n",
    "        input = np.clip(input, -100,100)\n",
    "        return np.exp(input)/(np.sum(np.exp(input)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def onehot(input):\n",
    "        result = np.zeros(10)\n",
    "        result[input] = 1\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def crossEntropyLoss(y,yHat):\n",
    "        loss = (-1/10.0) * np.sum(np.multiply(y, np.log(yHat+1e-10)) + np.multiply((1 - y), np.log(1 - (yHat+1e-10))))\n",
    "        return loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_sigmoid(input):\n",
    "        return Functions.sigmoid(input)*(1-Functions.sigmoid(input))\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_tanh(input):\n",
    "        return (1 - np.tanh(input)**2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_reLU(input):\n",
    "        answer = np.ones_like(input)\n",
    "        for val in input:\n",
    "            if val < 0:\n",
    "                val = 1\n",
    "        return answer\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_identity(input):\n",
    "        return 1\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot(input):\n",
    "        plt.plot(input)\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Loss over iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpFxAmhE9t2C",
    "outputId": "fdd02dd5-6147-4d7a-9d86-9cabebea2f81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▍                                       | 1/10 [00:22<03:18, 22.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The val_acc after this epoch is: [0.24783333333333332]\n",
      "The loss after this epoch is: 0.11292432851395517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▊                                   | 2/10 [00:43<02:55, 21.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The val_acc after this epoch is: [0.24783333333333332, 0.3006666666666667]\n",
      "The loss after this epoch is: 0.10291692733274684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hm/9gm9jdm90q5fz1jnmjxxsxh40000gn/T/ipykernel_42249/3917229754.py:33: RuntimeWarning: invalid value encountered in log\n",
      "  loss = (-1/10.0) * np.sum(np.multiply(y, np.log(yHat+1e-10)) + np.multiply((1 - y), np.log(1 - (yHat+1e-10))))\n",
      " 30%|█████████████▏                              | 3/10 [01:06<02:34, 22.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The val_acc after this epoch is: [0.24783333333333332, 0.3006666666666667, 0.36466666666666664]\n",
      "The loss after this epoch is: 0.08192266131495889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████▌                          | 4/10 [01:27<02:11, 21.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The val_acc after this epoch is: [0.24783333333333332, 0.3006666666666667, 0.36466666666666664, 0.31433333333333335]\n",
      "The loss after this epoch is: 0.09227391419931667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████                      | 5/10 [01:49<01:49, 21.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The val_acc after this epoch is: [0.24783333333333332, 0.3006666666666667, 0.36466666666666664, 0.31433333333333335, 0.27366666666666667]\n",
      "The loss after this epoch is: 0.07560400783694703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████▍                 | 6/10 [02:10<01:26, 21.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The val_acc after this epoch is: [0.24783333333333332, 0.3006666666666667, 0.36466666666666664, 0.31433333333333335, 0.27366666666666667, 0.35383333333333333]\n",
      "The loss after this epoch is: 0.07351595696034709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████▊             | 7/10 [02:32<01:04, 21.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The val_acc after this epoch is: [0.24783333333333332, 0.3006666666666667, 0.36466666666666664, 0.31433333333333335, 0.27366666666666667, 0.35383333333333333, 0.27116666666666667]\n",
      "The loss after this epoch is: 0.0831371473602934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████▏        | 8/10 [02:53<00:43, 21.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The val_acc after this epoch is: [0.24783333333333332, 0.3006666666666667, 0.36466666666666664, 0.31433333333333335, 0.27366666666666667, 0.35383333333333333, 0.27116666666666667, 0.2921666666666667]\n",
      "The loss after this epoch is: 0.06295558009839937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████▌    | 9/10 [03:15<00:21, 21.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The val_acc after this epoch is: [0.24783333333333332, 0.3006666666666667, 0.36466666666666664, 0.31433333333333335, 0.27366666666666667, 0.35383333333333333, 0.27116666666666667, 0.2921666666666667, 0.317]\n",
      "The loss after this epoch is: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [03:37<00:00, 21.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The val_acc after this epoch is: [0.24783333333333332, 0.3006666666666667, 0.36466666666666664, 0.31433333333333335, 0.27366666666666667, 0.35383333333333333, 0.27116666666666667, 0.2921666666666667, 0.317, 0.30733333333333335]\n",
      "The loss after this epoch is: 0.07029470999422348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data = PreProc()\n",
    "    #data.visualize(5)\n",
    "    train_x, test_x = data.flatten()\n",
    "    train_y, test_y = data.getLabels()\n",
    "    trainx = train_x/255\n",
    "    testx = test_x/255\n",
    "    neuralNet = FFNet(0,data.getInputSize(), 10)\n",
    "    neuralNet.addHiddenLayer(128)\n",
    "    neuralNet.addHiddenLayer(128)\n",
    "    neuralNet.addHiddenLayer(128)\n",
    "    neuralNet.addOutputLayer(10)\n",
    "    neuralNet.solidify()\n",
    "    neuralNet.fit(\"adam\",100, 0.001, \"relu\", trainx, train_y, 10)\n",
    "    neuralNet.evaluateNetwork(testx, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHfSx0jHSqtk",
    "outputId": "5e2dae53-035e-468c-98d7-d29b08d821f1"
   },
   "outputs": [],
   "source": [
    "#The class of FeedForwardNeuralNetwor\n",
    "\n",
    "class FFNet:\n",
    "    #constructor\n",
    "    def __init__(self,number_of_hidden_layers, number_of_inputs, number_of_outputs):\n",
    "        self.number_of_inputs = number_of_inputs\n",
    "        self.number_of_hidden_layers = number_of_hidden_layers\n",
    "        self.number_of_outputs = number_of_outputs\n",
    "        self.input = [0 for i in range(number_of_inputs)]\n",
    "        self.output = [0 for i in range(10)]\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        #self.hidden.append(np.random.random((number_of_inputs+1)))\n",
    "    \n",
    "    #Method for creating layers\n",
    "    def addHiddenLayer(self,number_of_neurons):\n",
    "        if(len(self.weights) == 0):\n",
    "            temp_weights = np.random.uniform(low = -0.5, high = 0.5, size = (number_of_neurons, self.number_of_inputs))\n",
    "            temp_biases = np.random.uniform(low = -0.5, high = 0.5, size = (number_of_neurons))\n",
    "        else:\n",
    "            prev_neurons = len(self.weights[len(self.weights) - 1])\n",
    "            temp_weights = np.random.uniform(low = -0.5, high = 0.5, size = (number_of_neurons, prev_neurons))\n",
    "            temp_biases = np.random.uniform(low = -0.5, high = 0.5, size = (number_of_neurons))\n",
    "        temp_weights = temp_weights/np.linalg.norm(temp_weights)\n",
    "        temp_biases = temp_biases/np.linalg.norm(temp_biases)\n",
    "        self.weights.append(temp_weights)\n",
    "        self.biases.append(temp_biases)\n",
    "    \n",
    "    def addOutputLayer(self, number_of_outputs):\n",
    "        if(len(self.weights) == 0):\n",
    "            #print(\"number of inputs: \"+str(self.number_of_inputs))\n",
    "            temp_weights = np.random.uniform(low = -0.5, high = 0.5, size = (number_of_outputs, self.number_of_inputs))\n",
    "            temp_biases = np.random.random(low = -0.5, high = 0.5, size = (number_of_outputs))\n",
    "        else:\n",
    "            prev_neurons = len(self.weights[len(self.weights) - 1])\n",
    "            temp_weights = np.random.uniform(low = -0.5, high = 0.5, size = (number_of_outputs, prev_neurons))\n",
    "            temp_biases = np.random.uniform(low = -0.5, high = 0.5, size = (number_of_outputs))\n",
    "        temp_weights = temp_weights/np.linalg.norm(temp_weights)\n",
    "        temp_biases = temp_biases/np.linalg.norm(temp_biases)\n",
    "        self.weights.append(temp_weights)\n",
    "        self.biases.append(temp_biases)\n",
    "\n",
    "    def solidify(self):\n",
    "        self.weights = np.array(self.weights, dtype = object)\n",
    "        self.biases = np.array(self.biases, dtype = object)\n",
    "\n",
    "    def getNetwork(self):\n",
    "        return self.weights,self.biases\n",
    "    \n",
    "    def ForwardProp(self, activate, output, inputLayer):\n",
    "        return Algorithms.ForwardProp(self.network, activate, output, inputLayer)\n",
    "    \n",
    "    def lossCalc(self, lossFunction, Y):\n",
    "        predY = self.historyA[(len(self.historyA)-1)]\n",
    "        return lossFunction(Y,self.predY)\n",
    "\n",
    "    def BackProp(self, a, h, dataPoint, dataLabel):\n",
    "        return Algorithms.BackProp(self.network, a, h, dataPoint, dataLabel)\n",
    "    \n",
    "    def fit(self, optimizer, batchSize, learningRate, activation, trainx, train_y, epochs):\n",
    "        \n",
    "        #break data into training and validation\n",
    "        indices = np.arange(len(trainx))\n",
    "        np.random.shuffle(indices)\n",
    "        trainx = trainx[indices]\n",
    "        train_y = train_y[indices]\n",
    "        \n",
    "        valTest_x = trainx[int(0.9*len(trainx)):]\n",
    "        valTest_y = train_y[int(0.9*len(train_y)):]\n",
    "        \n",
    "        trainx = trainx[:int(0.9*len(trainx))]\n",
    "        train_y = train_y[:int(0.9*len(train_y))]\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            activate = Functions.reLU\n",
    "            derivative = Functions.derivative_reLU\n",
    "            output = Functions.softmax\n",
    "        elif activation == \"tanh\":\n",
    "            activate = Functions.tanh\n",
    "            derivative = Functions.derivative_tanh\n",
    "            output = Functions.softmax\n",
    "        elif activation == \"identity\":\n",
    "            activate = Functions.identity\n",
    "            derivative = Functions.derivative_identity\n",
    "            output = Functions.softmax\n",
    "        else:\n",
    "            activate = Functions.sigmoid\n",
    "            derivative = Functions.derivative_sigmoid\n",
    "            output = Functions.softmax\n",
    "        \n",
    "        #print(optimizer)\n",
    "        \n",
    "        if optimizer == \"sgd\":\n",
    "            self.weights, self.biases = Algorithms.miniBatchGD(self.weights,self.biases , batchSize, learningRate, activate, output, derivative , trainx, train_y, valTest_x, valTest_y, epochs)\n",
    "        elif optimizer == \"momentum\":\n",
    "            self.weights, self.biases = Algorithms.miniBatchMGD(self.weights,self.biases , batchSize, learningRate, activate, output, derivative,  trainx, train_y, valTest_x, valTest_y, epochs)\n",
    "        elif optimizer == \"nag\":\n",
    "            self.weights, self.biases = Algorithms.miniBatchNAG(self.weights,self.biases , batchSize, learningRate,activate, output, derivative , trainx, train_y, valTest_x, valTest_y, epochs)\n",
    "        elif optimizer == \"rmsprop\":\n",
    "            self.weights, self.biases = Algorithms.RMSProp(self.weights,self.biases , batchSize, learningRate, activate, output, derivative,  trainx, train_y, valTest_x, valTest_y, epochs)\n",
    "        elif optimizer == \"adam\":\n",
    "            self.weights, self.biases = Algorithms.ADAM(self.weights,self.biases , batchSize, learningRate,activate, output, derivative,  trainx, train_y, valTest_x, valTest_y, epochs)\n",
    "        elif optimizer == \"nadam\":\n",
    "            self.weights, self.biases = Algorithms.NADAM(self.weights,self.biases , batchSize, learningRate, activate, output, derivative,  trainx, train_y, valTest_x, valTest_y, epochs)\n",
    "        else:\n",
    "            self.weights, self.biases = Algorithms.miniBatchGD(self.weights,self.biases , batchSize, learningRate, activate, output, derivative , trainx, train_y, valTest_x, valTest_y, epochs)\n",
    "        \n",
    "            \n",
    "    def evaluateNetwork(self, testx, tes_ty):\n",
    "        Algorithms.evaluateNetwork(self.weights, self.biases, testx, test_y)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "Bu5XtsgmjyaH"
   },
   "outputs": [],
   "source": [
    "class Algorithms:\n",
    "    @staticmethod\n",
    "    def ForwardProp(weights, bias, activate, output, inputLayer):\n",
    "        L = len(weights)-1\n",
    "        a = []\n",
    "        h = []\n",
    "        a.append(np.matmul(weights[0],inputLayer)+bias[0])\n",
    "        h.append(activate(a[0]))\n",
    "        for k in range(1,L):\n",
    "            a.append(np.matmul(weights[k],h[k-1].T)+bias[k])\n",
    "            h.append(activate(a[k]))\n",
    "        a.append(np.matmul(weights[L],h[L-1].T)+bias[L])\n",
    "        h.append(output(a[L]))\n",
    "        return a,h\n",
    "    @staticmethod\n",
    "    def BackProp(weights, biases, a, h, derivative, dataPoint, dataLabel):\n",
    "        L = len(weights)-1\n",
    "        gradaL = -(Functions.onehot(dataLabel)-h[len(h)-1])\n",
    "        dw = np.zeros_like(weights)\n",
    "        db = np.zeros_like(biases)\n",
    "        for k in range(L,0,-1):\n",
    "            gradW = np.outer(gradaL, h[k-1].T)\n",
    "            gradB = gradaL\n",
    "            dw[k] = gradW\n",
    "            db[k] = gradB\n",
    "\n",
    "            gradhL_1 = np.matmul(np.transpose(weights[k]),gradaL)\n",
    "            gradaL_1 = np.multiply(gradhL_1, derivative(a[k-1]))\n",
    "            gradaL = gradaL_1\n",
    "        dw[0] = np.outer(gradaL,dataPoint.T)\n",
    "        db[0] = gradaL\n",
    "        return dw, db\n",
    "\n",
    "    @staticmethod\n",
    "    def miniBatchMGD(weights, biases, batchSize, learningRate, activate, output, derivative, dataPoints, dataLabels, valTest_x, valTest_y, epochs):\n",
    "        lossTrack = []\n",
    "        validation = []\n",
    "        beta = 0.9\n",
    "        prevWeights = np.zeros_like(weights)\n",
    "        prevBiases = np.zeros_like(biases)\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            indices = np.arange(len(dataPoints))\n",
    "            np.random.shuffle(indices)\n",
    "            batchX = dataPoints[indices]\n",
    "            batchY = dataLabels[indices]\n",
    "            for i in range(math.ceil(len(dataPoints)/batchSize)):\n",
    "                trainer = batchX[i*batchSize:i*batchSize+batchSize]\n",
    "                labeler = batchY[i*batchSize:i*batchSize+batchSize]\n",
    "                batchLoss = 0.0\n",
    "                dw = np.zeros_like(weights)\n",
    "                db = np.zeros_like(biases)\n",
    "                for data in range(batchSize):\n",
    "                    a,h = Algorithms.ForwardProp(weights, biases , activate, output, trainer[data])\n",
    "                    currWeights, currBiases = Algorithms.BackProp(weights, biases, a, h, derivative, trainer[data], labeler[data])\n",
    "                    batchLoss += Functions.crossEntropyLoss(Functions.onehot(labeler[data]), h[-1])\n",
    "                    dw += currWeights\n",
    "                    db += currBiases\n",
    "                batchLoss /= batchSize\n",
    "                dw /= batchSize\n",
    "                db /= batchSize\n",
    "                momentumWeights = prevWeights*beta + dw*1.0\n",
    "                momentumBiases = prevBiases*beta + db*1.0\n",
    "                weights -= learningRate*momentumWeights\n",
    "                biases -= learningRate*momentumBiases\n",
    "                prevWeights = momentumWeights\n",
    "                prevBiases = momentumBiases\n",
    "                lossTrack.append(batchLoss)\n",
    "            validation.append(Algorithms.evaluateNetwork(weights, biases, valTest_x, valTest_y))\n",
    "            #print(\"The val_acc after this epoch is: \"+ str(validation))\n",
    "            Functions.plot(validation)\n",
    "        return weights, biases\n",
    "\n",
    "    @staticmethod\n",
    "    def ADAM(weights, biases, batchSize, learningRate, activate, output, derivative, dataPoints, dataLabels, valTest_x, valTest_y,epochs):\n",
    "        validation = []\n",
    "        lossTrack = []\n",
    "        beta1 = 0.9\n",
    "        beta2 = 0.99\n",
    "        epsilon = 0.000001\n",
    "        m_w = np.zeros_like(weights)\n",
    "        v_w = np.zeros_like(weights)\n",
    "        m_b = np.zeros_like(biases)\n",
    "        v_b = np.zeros_like(biases)\n",
    "        learnerRateW = np.full_like(weights, learningRate)\n",
    "        learnerRateB = np.full_like(biases, learningRate)\n",
    "        i = 0\n",
    "        \n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            indices = np.arange(len(dataPoints))\n",
    "            np.random.shuffle(indices)\n",
    "            batchX = dataPoints[indices]\n",
    "            batchY = dataLabels[indices]\n",
    "            for i in range(math.ceil(len(dataPoints)/batchSize)):\n",
    "                trainer = batchX[i*batchSize:i*batchSize+batchSize]\n",
    "                labeler = batchY[i*batchSize:i*batchSize+batchSize]\n",
    "                batchLoss = 0.0\n",
    "                dw = np.zeros_like(weights)\n",
    "                db = np.zeros_like(biases)\n",
    "                for data in range(batchSize):\n",
    "                    a,h = Algorithms.ForwardProp(weights, biases,activate, output, trainer[data])\n",
    "                    currWeights, currBiases = Algorithms.BackProp(weights, biases , a, h, derivative, trainer[data], labeler[data])\n",
    "                    batchLoss += Functions.crossEntropyLoss(Functions.onehot(labeler[data]), h[-1])\n",
    "                    dw += currWeights\n",
    "                    db += currBiases\n",
    "                batchLoss /= batchSize\n",
    "                dw /= batchSize\n",
    "                db /= batchSize\n",
    "                m_w = beta1*m_w + (1-beta1)*dw\n",
    "                m_b = beta1*m_b + (1-beta1)*db\n",
    "                v_w = v_w*beta2 + (1-beta2)*dw**2\n",
    "                v_b = v_b*beta2 + (1-beta2)*db**2\n",
    "                \n",
    "                m_w_hat = m_w/(1 - np.power(beta1, i+1))\n",
    "                m_b_hat = m_b/(1 - np.power(beta1, i+1))\n",
    "                v_w_hat = v_w/(1 - np.power(beta2, i+1))\n",
    "                v_b_hat = v_b/(1 - np.power(beta2, i+1))\n",
    "                \n",
    "                i+=1\n",
    "                \n",
    "                tempW = np.zeros_like(m_w)\n",
    "                tempB = np.zeros_like(m_b)\n",
    "                for i in range(len(dw)):\n",
    "                    tempW[i] = np.sqrt(v_w_hat[i])\n",
    "                    tempB[i] = np.sqrt(v_b_hat[i])\n",
    "                weights = weights - ((learnerRateW*dw)/(tempW + epsilon))\n",
    "                biases = biases - (learnerRateB*db)/(tempB+epsilon)\n",
    "                lossTrack.append(batchLoss)\n",
    "            validation.append(Algorithms.evaluateNetwork(weights, biases, valTest_x, valTest_y))\n",
    "            #print(\"The val_acc after this epoch is: \"+ str(validation))\n",
    "            Functions.plot(validation)\n",
    "            #print(\"The loss after this epoch is: \"+ str(batchLoss))\n",
    "        return weights,biases\n",
    "\n",
    "    @staticmethod\n",
    "    def NADAM(weights, biases, batchSize, learningRate, activate, output, derivative, dataPoints, dataLabels, valTest_x, valTest_y, epochs):\n",
    "        lossTrack = []\n",
    "        validation = []\n",
    "        beta1 = 0.9\n",
    "        beta2 = 0.99\n",
    "        epsilon = 0.000001\n",
    "        m_w = np.zeros_like(weights)\n",
    "        v_w = np.zeros_like(weights)\n",
    "        m_b = np.zeros_like(biases)\n",
    "        v_b = np.zeros_like(biases)\n",
    "        learnerRateW = np.full_like(weights, learningRate)\n",
    "        learnerRateB = np.full_like(biases, learningRate)\n",
    "        i = 0\n",
    "        \n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            indices = np.arange(len(dataPoints))\n",
    "            np.random.shuffle(indices)\n",
    "            batchX = dataPoints[indices]\n",
    "            batchY = dataLabels[indices]\n",
    "            for i in range(math.ceil(len(dataPoints)/batchSize)):\n",
    "                trainer = batchX[i*batchSize:i*batchSize+batchSize]\n",
    "                labeler = batchY[i*batchSize:i*batchSize+batchSize]\n",
    "                batchLoss = 0.0\n",
    "                dw = np.zeros_like(weights)\n",
    "                db = np.zeros_like(biases)\n",
    "                for data in range(batchSize):\n",
    "                    a,h = Algorithms.ForwardProp(weights - v_w*(beta1), biases - v_b*(beta1), activate, output, trainer[data])\n",
    "                    currWeights, currBiases = Algorithms.BackProp(weights - v_w*(beta1), biases - v_b*(beta1), a, h, derivative, trainer[data], labeler[data])\n",
    "                    batchLoss += Functions.crossEntropyLoss(Functions.onehot(labeler[data]), h[-1])\n",
    "                    dw += currWeights\n",
    "                    db += currBiases\n",
    "                batchLoss /= batchSize\n",
    "                dw /= batchSize\n",
    "                db /= batchSize\n",
    "                m_w = beta1*m_w + (1-beta1)*dw\n",
    "                m_b = beta1*m_b + (1-beta1)*db\n",
    "                v_w = v_w*beta2 + (1-beta2)*dw**2\n",
    "                v_b = v_b*beta2 + (1-beta2)*db**2\n",
    "                \n",
    "                m_w_hat = m_w/(1 - np.power(beta1, i+1))\n",
    "                m_b_hat = m_b/(1 - np.power(beta1, i+1))\n",
    "                v_w_hat = v_w/(1 - np.power(beta2, i+1))\n",
    "                v_b_hat = v_b/(1 - np.power(beta2, i+1))\n",
    "                \n",
    "                i+=1\n",
    "                \n",
    "                tempW = np.zeros_like(m_w)\n",
    "                tempB = np.zeros_like(m_b)\n",
    "                for j in range(len(dw)):\n",
    "                    tempW[j] = np.sqrt(v_w_hat[j])\n",
    "                    tempB[j] = np.sqrt(v_b_hat[j])\n",
    "                weights = weights - ((learnerRateW*dw)/(tempW + epsilon))\n",
    "                biases = biases - (learnerRateB*db)/(tempB+epsilon)\n",
    "                lossTrack.append(batchLoss)\n",
    "            validation.append(Algorithms.evaluateNetwork(weights, biases, valTest_x, valTest_y))\n",
    "            #print(\"The val_acc after this epoch is: \"+ str(validation))\n",
    "            Functions.plot(validation)\n",
    "            #print(\"The loss after this epoch is: \"+ str(batchLoss))\n",
    "        return weights,biases\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def miniBatchNAG(weights, biases, batchSize, learningRate, activate, output, derivative, dataPoints, dataLabels, valTest_x, valTest_y, epochs):\n",
    "        lossTrack = []\n",
    "        validation = []\n",
    "        beta = 0.9\n",
    "        prevWeights = np.zeros_like(weights)\n",
    "        prevBiases = np.zeros_like(biases)\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            indices = np.arange(len(dataPoints))\n",
    "            np.random.shuffle(indices)\n",
    "            batchX = dataPoints[indices]\n",
    "            batchY = dataLabels[indices]\n",
    "            for i in range(math.ceil(len(dataPoints)/batchSize)):\n",
    "                trainer = batchX[i*batchSize:i*batchSize+batchSize]\n",
    "                labeler = batchY[i*batchSize:i*batchSize+batchSize]\n",
    "                batchLoss = 0.0\n",
    "                tempWeights = np.zeros_like(weights)\n",
    "                tempBiases = np.zeros_like(biases)\n",
    "                for data in range(batchSize):\n",
    "                    a,h = Algorithms.ForwardProp(weights-prevWeights, biases-prevBiases, activate, output, trainer[data])\n",
    "                    currWeights, currBiases = Algorithms.BackProp(weights-prevWeights, biases-prevBiases, a, h, derivative, trainer[data], labeler[data])\n",
    "                    batchLoss += Functions.crossEntropyLoss(Functions.onehot(labeler[data]), h[-1])\n",
    "                    tempWeights += currWeights\n",
    "                    tempBiases += currBiases\n",
    "                batchLoss /= batchSize\n",
    "                tempWeights /= batchSize\n",
    "                tempBiases /= batchSize\n",
    "                momentumWeights = beta*prevWeights + tempWeights*1.0\n",
    "                momentumBiases = beta*prevBiases + tempBiases*1.0\n",
    "                weights = weights - learningRate*momentumWeights \n",
    "                biases = biases - learningRate*momentumBiases\n",
    "                prevWeights = momentumWeights\n",
    "                prevBiases = momentumBiases\n",
    "                lossTrack.append(batchLoss)\n",
    "            validation.append(Algorithms.evaluateNetwork(weights, biases, valTest_x, valTest_y))\n",
    "            #print(\"The val_acc after this epoch is: \"+ str(validation))\n",
    "            Functions.plot(validation)\n",
    "            #print(\"The loss after this epoch is: \"+ str(batchLoss))\n",
    "            Functions.plot(lossTrack)\n",
    "        return net\n",
    "    \n",
    "    @staticmethod\n",
    "    def RMSProp(weights, biases, batchSize, learningRate, activate, output, derivative, dataPoints, dataLabels, valTest_x, valTest_y, epochs):\n",
    "        lossTrack = []\n",
    "        validation = []\n",
    "        beta = 0.5\n",
    "        epsilon = 0.000001\n",
    "        momentumWeights = np.zeros_like(weights)\n",
    "        momentumBiases = np.zeros_like(biases)\n",
    "        learnerRateW = np.full_like(weights, learningRate)\n",
    "        learnerRateB = np.full_like(biases, learningRate)\n",
    "        \n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            indices = np.arange(len(dataPoints))\n",
    "            np.random.shuffle(indices)\n",
    "            batchX = dataPoints[indices]\n",
    "            batchY = dataLabels[indices]\n",
    "            for i in range(math.ceil(len(dataPoints)/batchSize)):\n",
    "                trainer = batchX[i*batchSize:i*batchSize+batchSize]\n",
    "                labeler = batchY[i*batchSize:i*batchSize+batchSize]\n",
    "                batchLoss = 0.0\n",
    "                dw = np.zeros_like(weights)\n",
    "                db = np.zeros_like(biases)\n",
    "                for data in range(batchSize):\n",
    "                    a,h = Algorithms.ForwardProp(weights, biases, activate, output, trainer[data])\n",
    "                    currWeights, currBiases = Algorithms.BackProp(weights, biases , a, h, derivative, trainer[data], labeler[data])\n",
    "                    batchLoss += Functions.crossEntropyLoss(Functions.onehot(labeler[data]), h[-1])\n",
    "                    dw += currWeights\n",
    "                    db += currBiases\n",
    "                batchLoss /= batchSize\n",
    "                dw /= batchSize\n",
    "                db /= batchSize\n",
    "                momentumWeights = momentumWeights*beta + (1-beta)*dw**2\n",
    "                momentumBiases = momentumBiases*beta + (1-beta)*db**2\n",
    "                tempW = np.zeros_like(momentumWeights)\n",
    "                tempB = np.zeros_like(momentumBiases)\n",
    "                for i in range(len(dw)):\n",
    "                    tempW[i] = np.sqrt(momentumWeights[i])\n",
    "                    tempB[i] = np.sqrt(momentumBiases[i])\n",
    "                weights = weights - ((learnerRateW)*dw/(tempW + epsilon))\n",
    "                biases = biases - (learnerRateB*db)/(tempB+epsilon)\n",
    "                lossTrack.append(batchLoss)\n",
    "            validation.append(Algorithms.evaluateNetwork(weights, biases, valTest_x, valTest_y))\n",
    "            #print(\"The val_acc after this epoch is: \"+ str(validation))\n",
    "            Functions.plot(validation)\n",
    "            #print(\"The loss after this epoch is: \"+ str(batchLoss))\n",
    "        return weights, biases\n",
    "\n",
    "    @staticmethod\n",
    "    def miniBatchGD(weights, biases, batchSize, learningRate, activate, output, derivative, dataPoints, dataLabels, valTest_x, valTest_y, epochs):\n",
    "        validation = []\n",
    "        lossTrack = []\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            indices = np.arange(len(dataPoints))\n",
    "            np.random.shuffle(indices)\n",
    "            batchX = dataPoints[indices]\n",
    "            batchY = dataLabels[indices]\n",
    "            dw = np.zeros_like(weights)\n",
    "            db = np.zeros_like(biases)\n",
    "            for i in range(math.ceil(len(dataPoints)/batchSize)):\n",
    "                trainer = batchX[i*batchSize:i*batchSize+batchSize]\n",
    "                labeler = batchY[i*batchSize:i*batchSize+batchSize]\n",
    "                batchLoss = 0.0\n",
    "                \n",
    "                for data in range(batchSize):\n",
    "                    a,h = Algorithms.ForwardProp(weights, biases , activate, output, trainer[data])\n",
    "                    tempw,tempb = Algorithms.BackProp(weights, biases, a, h, derivative, trainer[data], labeler[data])\n",
    "                    dw+=tempw\n",
    "                    db+=tempb\n",
    "                    batchLoss += Functions.crossEntropyLoss(Functions.onehot(labeler[data]), h[-1])\n",
    "                batchLoss /= batchSize\n",
    "                dw /= batchSize\n",
    "                db /= batchSize\n",
    "                weights = weights - learningRate*dw \n",
    "                biases = biases - learningRate*db\n",
    "                lossTrack.append(batchLoss)\n",
    "            #print(\"The loss after this epoch is: \"+ str(batchLoss))\n",
    "            validation.append(Algorithms.evaluateNetwork(weights, biases, valTest_x, valTest_y))\n",
    "            #print(\"The val_acc after this epoch is: \"+ str(validation))\n",
    "            Functions.plot(validation)\n",
    "            Functions.plot(lossTrack)\n",
    "        return weights, biases\n",
    "    \n",
    "    @staticmethod\n",
    "    def evaluateNetwork(weights, biases,test_x, test_y):\n",
    "        num_acc = 0\n",
    "        for i in range(len(test_x)):\n",
    "            a,h = Algorithms.ForwardProp(weights, biases, Functions.sigmoid, Functions.softmax, test_x[i])\n",
    "            h = np.array(h, dtype = object)\n",
    "            predY =   np.argmax(h[len(h)-1])\n",
    "            if test_y[i] == predY:\n",
    "                num_acc+=1\n",
    "        return (num_acc/len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = trainx[:int(0.9*len(trainx))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "valTest = trainx[int(0.9*len(trainx)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "R-YOAwnCmO3I",
    "outputId": "a052aca6-18cc-4d10-a3d6-17257b72ab4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cC3J4fScHacM"
   },
   "outputs": [],
   "source": [
    "a,h = Algorithms.ForwardProp(net, Functions.sigmoid, Functions.softmax, train_x[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L1KBO1xmaxu8",
    "outputId": "aa351438-35e1-4e7e-99c3-1a86fae078b7"
   },
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "id": "-DhPxwMbl6qX",
    "outputId": "5f0b4ef2-96a9-4a5b-f724-c8a1d521325e"
   },
   "outputs": [],
   "source": [
    "\n",
    "batchSize = 32\n",
    "gradient = np.zeros_like(net)\n",
    "lossTrack = []\n",
    "for epoch in tqdm(range(15)):\n",
    "    indices = np.arange(len(trainx))\n",
    "    np.random.shuffle(indices)\n",
    "    batchX = trainx[indices]\n",
    "    batchY = train_y[indices]\n",
    "    for i in range(math.ceil(len(trainx)/batchSize)):\n",
    "        trainer = batchX[i*batchSize:i*batchSize+batchSize]\n",
    "        labeler = batchY[i*batchSize:i*batchSize+batchSize]\n",
    "        batchLoss = 0.0\n",
    "        for data in range(batchSize):\n",
    "            a,h = Algorithms.ForwardProp(net, Functions.sigmoid, Functions.softmax, trainer[data])\n",
    "            currGrad = Algorithms.BackProp(net, a, h, trainer[data], labeler[data])\n",
    "            batchLoss += Functions.crossEntropyLoss(Functions.onehot(labeler[data]), h[-1])\n",
    "            gradient += currGrad\n",
    "        batchLoss /= 32\n",
    "        gradient /= 32\n",
    "        net = net - 0.01*gradient \n",
    "        lossTrack.append(batchLoss)\n",
    "    print(\"The loss after this epoch is: \"+ str(batchLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-hhR7Gex1BK9",
    "outputId": "57a17ae8-adef-4561-8bbb-a0206fa23106"
   },
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uckwQu3vbr9b"
   },
   "outputs": [],
   "source": [
    "gradient = neuralNet.BackProp(a,h,train_x[1], train_y[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trXRsTlNb0_1"
   },
   "outputs": [],
   "source": [
    "net = net - gradient*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SeXnBQQMbw_U",
    "outputId": "efc6c2b2-af74-4a82-f9e9-3c23fd302cd6"
   },
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CvzSP-M4btcN",
    "outputId": "001904ed-f2ec-4f76-b167-2678d1f33835"
   },
   "outputs": [],
   "source": [
    "np.argmax(np.array(h[L]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RcwywNK0blOr",
    "outputId": "d764dc8a-d727-443b-cb91-ba121fe78f26"
   },
   "outputs": [],
   "source": [
    "while np.argmax(np.array(h[L])):\n",
    "    for i in range(10):\n",
    "        a,h = Algorithms.ForwardProp(net,Functions.sigmoid, Functions.softmax, train_x[4])\n",
    "        gradient = neuralNet.BackProp(a,h,train_x[4], train_y[4])\n",
    "        net = net - 0.1*gradient\n",
    "        print(np.argmax(np.array(h[L])), end = \", \"),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-df0oArs006R",
    "outputId": "4218ed61-af21-4c62-cdac-3b2ec63efbe8"
   },
   "outputs": [],
   "source": [
    "train_y[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V0eqMHkIz3to",
    "outputId": "4a35e5fc-75b2-4bb2-de9a-8d103c5bb6c9"
   },
   "outputs": [],
   "source": [
    "num_acc = 0\n",
    "for i in range(len(test_x)):\n",
    "    a,h = Algorithms.ForwardProp(net, Functions.sigmoid, Functions.softmax, test_x[i])\n",
    "    h = np.array(h)\n",
    "    predY =   np.argmax(h[len(h)-1])\n",
    "    print(predY)\n",
    "    if test_y[i] == predY:\n",
    "        num_acc+=1\n",
    "print(num_acc/len(test_y), end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o84TF_u3yVv9",
    "outputId": "074c498e-5519-4f15-dc86-049be1c6382a"
   },
   "outputs": [],
   "source": [
    "len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TUcuGN-SzSyq",
    "outputId": "f6614617-7859-48d3-dff7-623f7622625c"
   },
   "outputs": [],
   "source": [
    "gradient[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OY0Zy9psDtk7"
   },
   "outputs": [],
   "source": [
    "for i in gradient[0]:\n",
    "    print(i, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I3YdLFqZU8Ci",
    "outputId": "52462d9f-b600-46f9-9403-a93bdb09c341"
   },
   "outputs": [],
   "source": [
    "gradient[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPDcvGye0lF7"
   },
   "outputs": [],
   "source": [
    "gradaL = -(Functions.onehot(train_y[1])-h[len(h)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PcCtxLxzFKVG"
   },
   "outputs": [],
   "source": [
    "gradhL_1 = np.matmul(np.transpose(net[(len(net)-1)]),aL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9xEUE6XKesg"
   },
   "outputs": [],
   "source": [
    "gradaL_1 = np.multiply(net[len(net)-1][:,:len(net[len(net)-1][0])-1], Functions.derivative_sigmoid(a[len(net)-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K72jzJOiJSR3"
   },
   "outputs": [],
   "source": [
    "gradW = np.outer(gradaL,h[len(net)-2].T)\n",
    "gradB = gradaL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XDbZT58hUOWW"
   },
   "outputs": [],
   "source": [
    "gradB.resize((len(gradB),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3-e7uWUUYd_",
    "outputId": "2dccdc5f-1f4f-4de9-ef20-bdc5f9e31910"
   },
   "outputs": [],
   "source": [
    "gradB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WdZHmwrRR2rx",
    "outputId": "df26a5dc-df87-4147-c06a-0d3df7c1d70d"
   },
   "outputs": [],
   "source": [
    "np.append(gradW,gradB.resize((10,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RDIXmbKHNo25",
    "outputId": "6d44560f-8280-4146-b7bd-dedf9486be76"
   },
   "outputs": [],
   "source": [
    "gradaL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7_71o1X06hg",
    "outputId": "5899546a-1304-47a4-e96b-f0f8edbce0ee"
   },
   "outputs": [],
   "source": [
    "a[len(net)-2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k65CaJIefUTY"
   },
   "outputs": [],
   "source": [
    "weights = net[0][:,:len(net[0][0])-1]\n",
    "bias = net[0][:,len(net[0][0])-1]\n",
    "temp = np.matmul(weights,train_x[0])+bias\n",
    "temp = temp/np.linalg.norm(temp)\n",
    "a = []\n",
    "a.append(temp)\n",
    "h = []\n",
    "h.append(Functions.sigmoid(a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZafDhQ7LmcUx"
   },
   "outputs": [],
   "source": [
    "weights = net[L][:,:len(net[L][0])-1]\n",
    "bias = net[L][:,len(net[L][0])-1]\n",
    "temp = np.matmul(weights,h[0])+bias\n",
    "temp = temp/np.linalg.norm(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "epu4dvEji2mG"
   },
   "outputs": [],
   "source": [
    "L = len(net)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tg0dnhLfheDu",
    "outputId": "93e6fdc7-9cf7-4236-b55e-550c4459f101"
   },
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qohv21-jxL88"
   },
   "outputs": [],
   "source": [
    "#The class of FeedForwardNeuralNetwor\n",
    "\n",
    "class FFNet:\n",
    "    #constructor\n",
    "    hidden = []\n",
    "    input = []\n",
    "    output = []\n",
    "    def __init__(self,number_of_hidden_layers, number_of_inputs, number_of_outputs):\n",
    "        self.number_of_inputs = number_of_inputs\n",
    "        self.number_of_hidden_layers = number_of_hidden_layers\n",
    "        self.number_of_outputs = number_of_outputs\n",
    "        #At the same time, the layers input layers mus also be initialized.\n",
    "\n",
    "        input = [0 for i in range(number_of_inputs)]\n",
    "        output = [0 for i in range(number_of_outputs)]\n",
    "        hidden = [[]]\n",
    "\n",
    "        #input and output layers are nothing but simple lists\n",
    "    \n",
    "    #Method for creating layers\n",
    "    def add_hidden_layer(number_of_neurons):\n",
    "        temp_weights = [0 for i in range(number_of_neurons+1)] #The +1 is for bias values\n",
    "        hidden.append(temp_weights)\n",
    "    \n",
    "    def backward_propagate(a,h, pred_y):\n",
    "        delthet[L] = -(exp(y) - pred_y) #with respect to output layer\n",
    "        for k in range(0,L-1,-1):\n",
    "            delthetw = np.matmul(delthet[k], h[k-1].T)\n",
    "            delthetb = delthet[k]\n",
    "            deltheth = np.matmul(weights[k].T, delthet[k])\n",
    "            delthet[k-1] = hadamard(deltheth, preac(a)) \n",
    "\n",
    "    def forward_propagate():\n",
    "        #here, we are calculating the preactivations and activations.\n",
    "        #we then store them in an array and return it.\n",
    "        \n",
    "        for k in range(number_of_levels-1):\n",
    "            a[k] = biases[k] + np.matmul(weights[k], h[k-1])\n",
    "            h[k] = g(a[k])\n",
    "        a[number_of_levels-1] = biases[number_of_levels] + np.matmul(weights[number_of_levels],h[number_of_levels-1])\n",
    "        pred_y = output(a[number_of_levels-1])\n",
    "        return a,h, pred_y\n",
    "\n",
    "\n",
    "    def gradient_descent():\n",
    "        a,h, pred_y = forward_propagate()\n",
    "        delthet = backward_propagate(a,h, pred_y)\n",
    "        thet += delthet\n",
    "\n",
    "    def fit(dataset):\n",
    "        for x,y in dataset:\n",
    "            loss = forward(x,y)\n",
    "            delthet = backward(loss)\n",
    "            thet += learn_rate*delthet\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
