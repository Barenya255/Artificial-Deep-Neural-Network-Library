{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vlcWrCZGiPRM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.datasets import fashion_mnist\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OLGP4dlAQjyZ",
    "outputId": "5e331d30-d8a9-46fb-f77a-3cf210f38da3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs22m028\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = {\n",
    "    'name': 'valAcc',\n",
    "    'goal': 'maximize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_dict = {\n",
    "    'optimizer': {\n",
    "        'values': ['nadam', 'momentum', 'nag', 'rmsprop', 'adam', 'sgd']\n",
    "        },\n",
    "    'fc_layer_size': {\n",
    "        'values': [32, 64, 128]\n",
    "        },\n",
    "    'number_of_layers': {\n",
    "        'values' : [3,4,5]\n",
    "        },\n",
    "    'epochs':{\n",
    "        'values' : [5,10]\n",
    "        },\n",
    "    'decay' : {\n",
    "        'values' : [0 ,0.0005, 0.5]\n",
    "        },\n",
    "    'learningRate' : {\n",
    "        'values' : [1e-3, 1e-4]\n",
    "        },\n",
    "    'batchSize' : {\n",
    "        'values' : [16, 32, 64]\n",
    "        },\n",
    "    'initialization' : {\n",
    "        'values' : ['random', 'Xavier']\n",
    "        },\n",
    "    'activation' : {\n",
    "        'values' : ['sigmoid', 'tanh', 'relu']\n",
    "        },\n",
    "    }\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'maximize', 'name': 'valAcc'},\n",
      " 'parameters': {'activation': {'values': ['sigmoid', 'tanh', 'relu']},\n",
      "                'batchSize': {'values': [16, 32, 64]},\n",
      "                'decay': {'values': [0, 0.0005, 0.5]},\n",
      "                'epochs': {'values': [5, 10]},\n",
      "                'fc_layer_size': {'values': [32, 64, 128]},\n",
      "                'initialization': {'values': ['random', 'Xavier']},\n",
      "                'learningRate': {'values': [0.001, 0.0001]},\n",
      "                'number_of_layers': {'values': [3, 4, 5]},\n",
      "                'optimizer': {'values': ['nadam',\n",
      "                                         'momentum',\n",
      "                                         'nag',\n",
      "                                         'rmsprop',\n",
      "                                         'adam',\n",
      "                                         'sgd']}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: bm9obr8d\n",
      "Sweep URL: https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"CS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config = None):\n",
    "    \n",
    "    with wandb.init(config = config):\n",
    "        #pprint.pprint(sweep_config)        \n",
    "        config = wandb.config\n",
    "        neuralNet = FFNet(0, len(trainx[0]), 10)\n",
    "        for layer in range(config.number_of_layers):\n",
    "            neuralNet.addHiddenLayer(config.fc_layer_size, config.initialization)\n",
    "        neuralNet.addOutputLayer(10, config.initialization)\n",
    "        neuralNet.solidify()\n",
    "        weights, biases = neuralNet.fit(config.optimizer,config.batchSize, config.learningRate, config.activation, trainx, train_y, config.decay, config.epochs)\n",
    "        print(Algorithms.evaluateNetwork(weights,biases,testx, test_y))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config = None):\n",
    "    \n",
    "    with wandb.init(config = config):\n",
    "        #pprint.pprint(sweep_config)        \n",
    "        config = wandb.config\n",
    "        neuralNet = FFNet(0, len(trainx[0]), 10)\n",
    "        for layer in range(config.number_of_layers):\n",
    "            neuralNet.addHiddenLayer(config.fc_layer_size, config.initialization)\n",
    "        neuralNet.addOutputLayer(10, config.initialization)\n",
    "        neuralNet.solidify()\n",
    "        config.optimizer = \"relu\"\n",
    "        weights, biases = neuralNet.fit(config.optimizer,config.batchSize, config.learningRate, config.activation, trainx, train_y, config.decay, config.epochs)\n",
    "        print(Algorithms.evaluateNetwork(weights,biases,testx, test_y))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q272w1ov with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchSize: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: Xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumber_of_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nag\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/barenya/Documents/GitHub/CS6910Assignment1/wandb/run-20230310_005924-q272w1ov</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs22m028/CS/runs/q272w1ov' target=\"_blank\">daily-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m028/CS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d' target=\"_blank\">https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs22m028/CS' target=\"_blank\">https://wandb.ai/cs22m028/CS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d' target=\"_blank\">https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs22m028/CS/runs/q272w1ov' target=\"_blank\">https://wandb.ai/cs22m028/CS/runs/q272w1ov</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [01:15<00:00,  7.60s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad6a324bdbe4dbfb7e1148213b499f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>valAcc</td><td>▁▁▂▅▆█▇▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>valAcc</td><td>0.30117</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">daily-sweep-1</strong> at: <a href='https://wandb.ai/cs22m028/CS/runs/q272w1ov' target=\"_blank\">https://wandb.ai/cs22m028/CS/runs/q272w1ov</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230310_005924-q272w1ov/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run q272w1ov errored: NameError(\"name 'net' is not defined\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run q272w1ov errored: NameError(\"name 'net' is not defined\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5l32sgjy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchSize: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: Xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumber_of_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/barenya/Documents/GitHub/CS6910Assignment1/wandb/run-20230310_010056-5l32sgjy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs22m028/CS/runs/5l32sgjy' target=\"_blank\">distinctive-sweep-2</a></strong> to <a href='https://wandb.ai/cs22m028/CS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d' target=\"_blank\">https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs22m028/CS' target=\"_blank\">https://wandb.ai/cs22m028/CS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d' target=\"_blank\">https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs22m028/CS/runs/5l32sgjy' target=\"_blank\">https://wandb.ai/cs22m028/CS/runs/5l32sgjy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]/var/folders/hm/9gm9jdm90q5fz1jnmjxxsxh40000gn/T/ipykernel_66000/3847868567.py:33: RuntimeWarning: invalid value encountered in log\n",
      "  loss = (-1/10.0) * np.sum(np.multiply(y, np.log(yHat+1e-10)) + np.multiply((1 - y), np.log(1 - (yHat+1e-10))))\n",
      "/var/folders/hm/9gm9jdm90q5fz1jnmjxxsxh40000gn/T/ipykernel_66000/986472836.py:173: RuntimeWarning: overflow encountered in square\n",
      "  v_w = v_w*beta2 + (1-beta2)*dw**2\n",
      "/var/folders/hm/9gm9jdm90q5fz1jnmjxxsxh40000gn/T/ipykernel_66000/986472836.py:174: RuntimeWarning: overflow encountered in square\n",
      "  v_b = v_b*beta2 + (1-beta2)*db**2\n",
      "/var/folders/hm/9gm9jdm90q5fz1jnmjxxsxh40000gn/T/ipykernel_66000/986472836.py:7: RuntimeWarning: invalid value encountered in matmul\n",
      "  a.append(np.matmul(weights[0],inputLayer)+bias[0])\n",
      "100%|███████████████████████████████████████████| 10/10 [02:53<00:00, 17.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>valAcc</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>valAcc</td><td>0.09983</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distinctive-sweep-2</strong> at: <a href='https://wandb.ai/cs22m028/CS/runs/5l32sgjy' target=\"_blank\">https://wandb.ai/cs22m028/CS/runs/5l32sgjy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230310_010056-5l32sgjy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7c66yi7f with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchSize: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: Xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumber_of_layers: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/barenya/Documents/GitHub/CS6910Assignment1/wandb/run-20230310_010407-7c66yi7f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs22m028/CS/runs/7c66yi7f' target=\"_blank\">fine-sweep-3</a></strong> to <a href='https://wandb.ai/cs22m028/CS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d' target=\"_blank\">https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs22m028/CS' target=\"_blank\">https://wandb.ai/cs22m028/CS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d' target=\"_blank\">https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs22m028/CS/runs/7c66yi7f' target=\"_blank\">https://wandb.ai/cs22m028/CS/runs/7c66yi7f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]/var/folders/hm/9gm9jdm90q5fz1jnmjxxsxh40000gn/T/ipykernel_66000/986472836.py:126: RuntimeWarning: overflow encountered in divide\n",
      "  weights = weights - ((learnerRateW*(dw + decay*weights))/(tempW + epsilon))\n",
      "/var/folders/hm/9gm9jdm90q5fz1jnmjxxsxh40000gn/T/ipykernel_66000/986472836.py:27: RuntimeWarning: invalid value encountered in matmul\n",
      "  gradhL_1 = np.matmul(np.transpose(weights[k]),gradaL)\n",
      "/var/folders/hm/9gm9jdm90q5fz1jnmjxxsxh40000gn/T/ipykernel_66000/986472836.py:126: RuntimeWarning: invalid value encountered in subtract\n",
      "  weights = weights - ((learnerRateW*(dw + decay*weights))/(tempW + epsilon))\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:41<00:00,  8.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>valAcc</td><td>▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>valAcc</td><td>0.09967</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fine-sweep-3</strong> at: <a href='https://wandb.ai/cs22m028/CS/runs/7c66yi7f' target=\"_blank\">https://wandb.ai/cs22m028/CS/runs/7c66yi7f</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230310_010407-7c66yi7f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ftqi01h6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchSize: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: random\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumber_of_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43242dc403db4219a9058a0d04816066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016753200682190557, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/barenya/Documents/GitHub/CS6910Assignment1/wandb/run-20230310_010508-ftqi01h6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs22m028/CS/runs/ftqi01h6' target=\"_blank\">woven-sweep-4</a></strong> to <a href='https://wandb.ai/cs22m028/CS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d' target=\"_blank\">https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs22m028/CS' target=\"_blank\">https://wandb.ai/cs22m028/CS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d' target=\"_blank\">https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs22m028/CS/runs/ftqi01h6' target=\"_blank\">https://wandb.ai/cs22m028/CS/runs/ftqi01h6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▍                                       | 1/10 [00:26<03:59, 26.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after this epoch is: 0.3253184304995294\n",
      "The loss after this epoch is: 0.3251389053787964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▊                                   | 2/10 [00:53<03:32, 26.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after this epoch is: 0.324941540874355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▌                          | 4/10 [01:47<02:42, 27.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after this epoch is: 0.32522583095232716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████                      | 5/10 [02:13<02:12, 26.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after this epoch is: 0.3251658648574716\n",
      "The loss after this epoch is: 0.3251150858897344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████▍                 | 6/10 [02:40<01:46, 26.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after this epoch is: 0.3252235218426619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████▊             | 7/10 [03:06<01:19, 26.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after this epoch is: 0.32511100943055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████▏        | 8/10 [03:33<00:53, 26.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after this epoch is: 0.32511811168843646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [04:26<00:00, 26.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after this epoch is: 0.3250835461569128\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71e05ce328d4dc98b5bcb04c05615f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>valAcc</td><td>▁▃▁█▇▂▃▅▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>valAcc</td><td>0.09783</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">woven-sweep-4</strong> at: <a href='https://wandb.ai/cs22m028/CS/runs/ftqi01h6' target=\"_blank\">https://wandb.ai/cs22m028/CS/runs/ftqi01h6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230310_010508-ftqi01h6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5fed92dx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchSize: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitialization: random\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumber_of_layers: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nag\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/barenya/Documents/GitHub/CS6910Assignment1/wandb/run-20230310_010954-5fed92dx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs22m028/CS/runs/5fed92dx' target=\"_blank\">northern-sweep-5</a></strong> to <a href='https://wandb.ai/cs22m028/CS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d' target=\"_blank\">https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs22m028/CS' target=\"_blank\">https://wandb.ai/cs22m028/CS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d' target=\"_blank\">https://wandb.ai/cs22m028/CS/sweeps/bm9obr8d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs22m028/CS/runs/5fed92dx' target=\"_blank\">https://wandb.ai/cs22m028/CS/runs/5fed92dx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [01:20<00:00, 16.04s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>valAcc</td><td>▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>valAcc</td><td>0.09683</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">northern-sweep-5</strong> at: <a href='https://wandb.ai/cs22m028/CS/runs/5fed92dx' target=\"_blank\">https://wandb.ai/cs22m028/CS/runs/5fed92dx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230310_010954-5fed92dx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 5fed92dx errored: NameError(\"name 'net' is not defined\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 5fed92dx errored: NameError(\"name 'net' is not defined\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train, count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TfO2B6v6BVWj"
   },
   "outputs": [],
   "source": [
    "class PreProc:\n",
    "    def __init__(self):\n",
    "        (self.trainx,self.trainy),(self.testx, self.testy) = fashion_mnist.load_data()\n",
    "        \n",
    "    def visualize(self,n):\n",
    "        for i in range(n):\n",
    "            plt.subplot(330+1+i) # ask someone why??\n",
    "            plt.imshow(self.trainx[i], cmap = plt.get_cmap('gray'))\n",
    "        plt.show()\n",
    "        \n",
    "    def flattenAndCentralize(self):\n",
    "        trainx_flattened = np.copy(self.trainx).astype('float64')\n",
    "        testx_flattened = np.copy(self.testx).astype('float64')\n",
    "        augment(trainx_flattened)\n",
    "        trainx_flattened -= np.mean(trainx_flattened)\n",
    "        testx_flattened -= np.mean(testx_flattened)\n",
    "        trainx_flattened.shape = (60000,784)\n",
    "        testx_flattened.shape = (10000,784)\n",
    "        return trainx_flattened,testx_flattened\n",
    "    \n",
    "    def augment(trainx):\n",
    "        for image in trainx:\n",
    "            \n",
    "    \n",
    "    def getLabels(self):\n",
    "        return self.trainy, self.testy\n",
    "    \n",
    "    def getInputSize(self):\n",
    "        return len(self.trainx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4HhzRi0xhOLc"
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "7BwoVy0bPFA0"
   },
   "outputs": [],
   "source": [
    "class Functions:\n",
    "    @staticmethod\n",
    "    def sigmoid(input):\n",
    "        input = np.clip(input, -100,100)\n",
    "        return  1.0/(1.0+np.exp(-input))\n",
    "    \n",
    "    @staticmethod\n",
    "    def reLU(input):\n",
    "        return np.maximum(0,input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def tanh(input):\n",
    "        return np.tanh(input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def identity(input):\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(input):\n",
    "        input = np.clip(input, -100,100)\n",
    "        return np.exp(input)/(np.sum(np.exp(input)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def onehot(input):\n",
    "        result = np.zeros(10)\n",
    "        result[input] = 1\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def crossEntropyLoss(y,yHat):\n",
    "        loss = (-1/10.0) * np.sum(np.multiply(y, np.log(yHat+1e-10)) + np.multiply((1 - y), np.log(1 - (yHat+1e-10))))\n",
    "        return loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_sigmoid(input):\n",
    "        return Functions.sigmoid(input)*(1-Functions.sigmoid(input))\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_tanh(input):\n",
    "        return (1 - (np.tanh(input)**2))\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_reLU(input):\n",
    "        return np.where(input > 0, 1, 0)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_identity(input):\n",
    "        return 1\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot(input):\n",
    "        plt.plot(input)\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Loss over iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpFxAmhE9t2C",
    "outputId": "fdd02dd5-6147-4d7a-9d86-9cabebea2f81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data = PreProc()\n",
    "    #data.visualize(5)\n",
    "    train_x, test_x = data.flattenAndCentralize()\n",
    "    trainx = train_x/255.0\n",
    "    testx = test_x/255.0\n",
    "    train_y, test_y = data.getLabels()\n",
    "    neuralNet = FFNet(0, len(trainx[0]), 10)\n",
    "    neuralNet.addHiddenLayer(128, \"uniform\")\n",
    "    neuralNet.addHiddenLayer(128, \"uniform\")\n",
    "    neuralNet.addHiddenLayer(128, \"uniform\")\n",
    "    neuralNet.addHiddenLayer(128, \"uniform\")\n",
    "    neuralNet.addHiddenLayer(128, \"uniform\")\n",
    "    \n",
    "    neuralNet.addOutputLayer(10, \"uniform\")\n",
    "    neuralNet.solidify()\n",
    "    #print(trainx.shape)\n",
    "    #wandb.init()\n",
    "    weights,biases = neuralNet.fit(\"adam\",64, 0.0001, \"tanh\", trainx, train_y, 0, 10)\n",
    "    print(Algorithms.evaluateNetwork(weights,biases,testx, test_y))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[-0.05315978, -0.06470103, -0.05763442, ..., -0.06875392,\n",
       "               -0.05449175, -0.05460499],\n",
       "              [-0.10112775, -0.10645273, -0.09574637, ..., -0.08414606,\n",
       "               -0.07244215, -0.09358254],\n",
       "              [-0.09480948, -0.10329461, -0.09518375, ..., -0.08292364,\n",
       "               -0.08790747, -0.09871433],\n",
       "              ...,\n",
       "              [ 0.00432543, -0.00263004,  0.00509826, ..., -0.00184554,\n",
       "                0.00630984, -0.01028103],\n",
       "              [-0.03280518, -0.04734088, -0.03569725, ..., -0.06858864,\n",
       "               -0.04768746, -0.02892765],\n",
       "              [-0.02695263, -0.02978223, -0.01302951, ..., -0.04506395,\n",
       "               -0.02377795, -0.01909168]])                             ,\n",
       "       array([[ 0.0098093 ,  0.02532047,  0.02744661, ..., -0.02055589,\n",
       "               -0.06878926,  0.02354353],\n",
       "              [ 0.13552526, -0.0383828 ,  0.12457816, ..., -0.00320767,\n",
       "                0.07568057, -0.0366282 ],\n",
       "              [ 0.22117392,  0.13159745,  0.10735194, ...,  0.0036538 ,\n",
       "                0.13234219, -0.06090568],\n",
       "              ...,\n",
       "              [ 0.08133976,  0.06614792, -0.11728795, ..., -0.05542537,\n",
       "               -0.02264293,  0.02217091],\n",
       "              [-0.04182844,  0.11524165,  0.0135077 , ..., -0.00202072,\n",
       "                0.08863964,  0.15306862],\n",
       "              [-0.05853403,  0.10908477,  0.05096559, ...,  0.02243745,\n",
       "                0.06964098,  0.03273722]])                             ,\n",
       "       array([[-0.02365469,  0.16899769,  0.07393104, ..., -0.02692622,\n",
       "               -0.09999503, -0.0423575 ],\n",
       "              [ 0.02719286, -0.02213358,  0.00926852, ..., -0.03347449,\n",
       "               -0.01535037, -0.01127865],\n",
       "              [ 0.02450653,  0.04255239,  0.13671037, ...,  0.12389073,\n",
       "                0.02658473, -0.08068862],\n",
       "              ...,\n",
       "              [ 0.00099114,  0.00282702,  0.0097216 , ...,  0.35552987,\n",
       "                0.10904746,  0.04709504],\n",
       "              [-0.05247321,  0.00268825, -0.01397439, ..., -0.41118372,\n",
       "                0.06036815,  0.11714008],\n",
       "              [ 0.0156807 ,  0.08101619,  0.03649474, ..., -0.06424382,\n",
       "               -0.07988535, -0.03550322]])                             ,\n",
       "       array([[-1.60053522e-01,  8.12879209e-02, -2.65843413e-01,\n",
       "               -8.06377012e-02,  3.09134660e-02, -8.58751359e-02,\n",
       "                6.91045317e-02, -2.95485963e-03, -2.21758824e-02,\n",
       "                4.45536073e-02,  1.73080267e-02, -2.59617323e-02,\n",
       "                1.47814092e-01,  1.29452197e-01,  1.56232052e-02,\n",
       "                7.60962612e-02, -1.45969624e-01,  1.04610470e-01,\n",
       "                3.87625171e-02,  8.70262996e-02, -5.03977683e-02,\n",
       "               -2.93414648e-01, -2.77199735e-02, -7.75493087e-02,\n",
       "                1.61284051e-01,  1.31849506e-02, -7.52959705e-02,\n",
       "               -2.28010098e-01, -1.68661658e-01, -2.28571416e-02,\n",
       "                3.09795542e-02,  1.04584234e-02],\n",
       "              [-1.31268602e-01, -1.47101177e-02,  5.22495966e-02,\n",
       "               -5.75893519e-02,  4.46214577e-02, -9.72061626e-02,\n",
       "                2.61878945e-04, -5.11172968e-03, -1.83773893e-01,\n",
       "                3.57270762e-02, -4.30041175e-02,  1.05403758e-01,\n",
       "                4.89357942e-02, -1.55254377e-01,  7.41748364e-03,\n",
       "               -1.61170521e-01, -1.73439166e-01, -3.34333354e-02,\n",
       "                1.15398834e-01, -2.27087349e-01, -9.06326760e-02,\n",
       "               -1.61850070e-01, -2.28667292e-01,  8.91215927e-02,\n",
       "               -2.07014400e-01, -1.13778748e-02,  1.22060953e-01,\n",
       "                4.22233903e-01,  1.86752834e-01,  1.34236109e-01,\n",
       "               -1.23636351e-02, -1.56927297e-01],\n",
       "              [-8.59415892e-02, -5.89969623e-02, -8.11255256e-02,\n",
       "                4.16657673e-02,  1.40165236e-01, -9.02911458e-02,\n",
       "               -7.09083035e-02, -4.16550321e-03, -4.75583184e-02,\n",
       "                5.47464465e-02,  9.89462973e-02, -1.61647407e-01,\n",
       "               -5.15420999e-01,  5.28303784e-02, -2.25171697e-01,\n",
       "                4.88989530e-02, -2.62883074e-01,  5.56831480e-02,\n",
       "                3.67461703e-02, -3.94045654e-02,  1.13874317e-01,\n",
       "               -1.63745717e-01, -8.52138384e-02, -7.68106409e-02,\n",
       "                6.30875014e-02,  1.24826020e-01, -3.48330782e-02,\n",
       "               -6.06005464e-02,  1.08462388e-01,  8.09987122e-02,\n",
       "               -6.21506615e-02, -7.67469793e-02],\n",
       "              [-8.47341413e-02,  6.14818550e-02, -1.27435524e-01,\n",
       "                7.51584673e-02,  9.27388268e-02,  3.79248551e-02,\n",
       "               -9.09418854e-02,  8.68746642e-02, -6.25060743e-02,\n",
       "                4.75267676e-02, -1.02654923e-01,  2.68334263e-02,\n",
       "                4.55314486e-02,  7.16103098e-02, -1.42421194e-01,\n",
       "               -1.18209738e-01, -4.00632752e-02,  2.63978998e-02,\n",
       "                3.93163777e-02, -6.92254473e-04, -7.85607963e-02,\n",
       "               -1.66768336e-01, -1.00753150e-01,  1.01203553e-01,\n",
       "               -2.39995268e-01, -7.47461985e-02,  4.54629160e-02,\n",
       "               -3.37276034e-01, -1.35164976e-01,  3.20445317e-02,\n",
       "                1.14541291e-01, -2.84902143e-03],\n",
       "              [ 6.00251570e-02,  7.58264181e-03, -4.44336966e-01,\n",
       "               -1.94398705e-02,  9.75548380e-02,  1.49239296e-01,\n",
       "               -3.44570207e-02,  1.88060927e-02, -4.12783368e-02,\n",
       "                6.37915956e-02,  1.42433746e-01, -1.94250222e-01,\n",
       "               -1.49976968e-01,  1.15125485e-01, -1.61673579e-02,\n",
       "               -7.05741543e-02, -8.56350882e-02,  7.39660511e-03,\n",
       "               -2.22445115e-01, -8.14267497e-02, -3.41013112e-02,\n",
       "               -3.82275979e-01, -9.89236032e-02, -1.86540514e-02,\n",
       "               -3.77881035e-01,  3.44841662e-02,  1.40335564e-01,\n",
       "               -3.38415300e-01,  1.17378115e-01,  1.41706323e-03,\n",
       "               -1.00295445e-01, -1.28134803e-01],\n",
       "              [-2.22100566e-03,  5.89348395e-02,  2.85375692e-02,\n",
       "               -1.15857757e-01, -2.61167029e-01, -1.20175645e-01,\n",
       "                5.70266059e-02,  7.06902311e-03,  1.82329924e-02,\n",
       "               -1.08418008e-01,  4.73136371e-03,  7.66842499e-02,\n",
       "               -3.81446493e-01, -2.21687359e-01, -4.51367061e-02,\n",
       "                9.31098810e-02,  1.92731211e-01, -1.25138861e-02,\n",
       "               -3.55015842e-01, -9.82988015e-02, -1.57014145e-01,\n",
       "                1.49264894e-01, -1.11621029e-02,  9.10950315e-02,\n",
       "               -3.49296287e-01,  3.08639898e-02,  8.54298442e-02,\n",
       "               -1.95303316e-01, -5.30518084e-02,  1.45130086e-02,\n",
       "               -1.14571045e-01,  4.74880717e-03],\n",
       "              [-3.11007056e-03,  9.47650935e-02, -3.83969173e-01,\n",
       "                1.17861064e-01,  5.87146635e-02, -6.34321177e-02,\n",
       "               -6.66822253e-02,  1.00611807e-02,  6.94124539e-02,\n",
       "               -9.22297815e-02,  2.96449849e-02, -3.42301888e-02,\n",
       "                7.58747258e-02,  9.25234893e-02, -2.68067574e-01,\n",
       "                3.13928668e-02, -5.49997661e-02,  1.01358740e-01,\n",
       "               -1.29531454e-01,  1.63099797e-01, -1.08763346e-02,\n",
       "               -3.09552424e-01,  5.47919542e-02, -2.18524758e-02,\n",
       "               -2.34765895e-03, -8.90770899e-02,  1.48040240e-02,\n",
       "               -1.29861785e-01,  4.23883232e-02,  2.75668876e-02,\n",
       "               -3.30300864e-02, -3.11643469e-01],\n",
       "              [ 1.75923188e-01, -1.86403882e-03,  1.93996292e-01,\n",
       "               -2.94802201e-02, -2.10445126e-01, -1.74608620e-02,\n",
       "                4.29813314e-03, -7.43068264e-02,  2.29258087e-02,\n",
       "               -2.93670755e-01, -2.52655036e-01, -1.00027537e-01,\n",
       "               -2.27328059e-01, -1.37177842e-01,  7.94950636e-02,\n",
       "               -1.02124925e-01,  5.30791523e-02, -3.27917491e-01,\n",
       "               -3.39979401e-01, -1.39919418e-01, -1.95220175e-01,\n",
       "                1.70419757e-01,  1.31873599e-01, -2.21581005e-01,\n",
       "               -2.45511877e-01, -3.34357418e-02, -2.63273613e-01,\n",
       "                1.99878514e-02,  2.23929817e-03, -2.34475493e-01,\n",
       "               -2.83292355e-03,  8.71513854e-02],\n",
       "              [ 1.05159894e-01,  3.35882056e-02, -2.39134186e-01,\n",
       "                5.14064969e-02, -1.70195752e-01, -3.03905591e-02,\n",
       "                8.47858187e-03, -2.39140859e-02,  1.20499221e-01,\n",
       "               -5.70308114e-02, -7.45236647e-02, -1.54632272e-01,\n",
       "                8.66833472e-02,  5.11159024e-02,  9.59869419e-02,\n",
       "                9.47301510e-02,  2.06677198e-02,  5.39495535e-02,\n",
       "                2.78791165e-02,  1.32269731e-01,  4.96126901e-02,\n",
       "               -1.90376256e-01,  1.08098258e-01, -2.08510990e-01,\n",
       "                3.51976627e-02, -1.98192282e-02, -8.84437226e-02,\n",
       "                5.94568547e-02,  1.88093785e-01, -4.52857913e-02,\n",
       "               -8.03323899e-02, -2.77692931e-02],\n",
       "              [ 7.76815571e-02, -3.62047258e-02, -7.85932921e-03,\n",
       "                5.86324864e-02, -1.49481610e-01,  9.58921079e-02,\n",
       "               -5.52923766e-02,  2.10329029e-02, -1.43014326e-02,\n",
       "               -4.62875024e-02, -5.21910864e-01,  4.93208922e-02,\n",
       "               -4.89425327e-01, -6.58294310e-03,  7.29445263e-02,\n",
       "               -1.53370166e-01,  7.91034663e-02,  5.54204621e-03,\n",
       "               -1.27307776e-01, -4.22128075e-02,  1.10705818e-01,\n",
       "               -1.87793159e-02,  6.07330034e-02, -1.75034038e-01,\n",
       "               -5.27121767e-01, -4.22842588e-02, -5.06646263e-02,\n",
       "               -2.12303177e-01, -4.87768035e-02, -3.73611268e-01,\n",
       "                1.47893776e-01,  7.31557940e-02]])               ],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHfSx0jHSqtk",
    "outputId": "5e2dae53-035e-468c-98d7-d29b08d821f1"
   },
   "outputs": [],
   "source": [
    "#The class of FeedForwardNeuralNetwor\n",
    "\n",
    "class FFNet:\n",
    "    #constructor\n",
    "    def __init__(self,number_of_hidden_layers, number_of_inputs, number_of_outputs):\n",
    "        self.number_of_inputs = number_of_inputs\n",
    "        self.number_of_hidden_layers = number_of_hidden_layers\n",
    "        self.number_of_outputs = number_of_outputs\n",
    "        self.input = [0 for i in range(number_of_inputs)]\n",
    "        self.output = [0 for i in range(10)]\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        #self.hidden.append(np.random.random((number_of_inputs+1)))\n",
    "    \n",
    "    #Method for creating layers\n",
    "    def addHiddenLayer(self,number_of_neurons, initialization):\n",
    "        if(len(self.weights) == 0):\n",
    "            temp_weights = np.random.normal(loc = 0, scale = 0.01, size = (number_of_neurons, self.number_of_inputs))\n",
    "            temp_biases = np.random.normal(loc = 0, scale = 0.01, size = (number_of_neurons))\n",
    "            if initialization == \"xavier\":\n",
    "                temp_weights = np.random.randn(number_of_neurons, self.number_of_inputs)*np.sqrt(2/(self.number_of_inputs+number_of_neurons))\n",
    "                #temp_biases = np.random.randn(number_of_neurons)*np.sqrt(1/(number_of_neurons))\n",
    "        else:\n",
    "            prev_neurons = len(self.weights[len(self.weights) - 1])\n",
    "            temp_weights = np.random.normal(loc = 0, scale = 0.01, size = (number_of_neurons, prev_neurons))\n",
    "            temp_biases = np.random.normal(loc = 0, scale = 0.01, size = (number_of_neurons))\n",
    "            if initialization == \"xavier\":\n",
    "                temp_weights = np.random.randn(number_of_neurons, prev_neurons)*np.sqrt(2/(number_of_neurons+prev_neurons))\n",
    "                #temp_biases = np.random.randn(number_of_neurons)*np.sqrt(1/(number_of_neurons))\n",
    "        temp_weights = temp_weights/np.linalg.norm(temp_weights)\n",
    "        temp_biases = temp_biases/np.linalg.norm(temp_biases)\n",
    "        self.weights.append(temp_weights)\n",
    "        self.biases.append(temp_biases)\n",
    "    \n",
    "    def addOutputLayer(self, number_of_outputs, initialization):\n",
    "        if(len(self.weights) == 0):\n",
    "            #print(\"number of inputs: \"+str(self.number_of_inputs))\n",
    "            temp_weights = np.random.normal(loc = 0, scale = 0.01, size = (number_of_outputs, self.number_of_inputs))\n",
    "            temp_biases = np.random.normal(loc = 0, scale = 0.01, size = (number_of_outputs))\n",
    "            if initialization == \"xavier\":\n",
    "                temp_weights = np.random.randn(number_of_outputs, self.number_of_inputs)*np.sqrt(2/(self.number_of_inputs+number_of_outputs))\n",
    "        else:\n",
    "            prev_neurons = len(self.weights[len(self.weights) - 1])\n",
    "            temp_weights = np.random.normal(loc = 0, scale = 0.01, size = (number_of_outputs, prev_neurons))\n",
    "            temp_biases = np.random.normal(loc = 0, scale = 0.01, size = (number_of_outputs))\n",
    "            if initialization == \"xavier\":\n",
    "                temp_weights = np.random.randn(number_of_outputs, prev_neurons)*np.sqrt(2/(prev_neurons+number_of_outputs))\n",
    "                \n",
    "        temp_weights = temp_weights/np.linalg.norm(temp_weights)\n",
    "        temp_biases = temp_biases/np.linalg.norm(temp_biases)\n",
    "        self.weights.append(temp_weights)\n",
    "        self.biases.append(temp_biases)\n",
    "\n",
    "    def solidify(self):\n",
    "        self.weights = np.array(self.weights, dtype = object)\n",
    "        self.biases = np.array(self.biases, dtype = object)\n",
    "\n",
    "    def getNetwork(self):\n",
    "        return self.weights,self.biases\n",
    "    \n",
    "    def ForwardProp(self, activate, output, inputLayer):\n",
    "        return Algorithms.ForwardProp(self.network, activate, output, inputLayer)\n",
    "    \n",
    "    def lossCalc(self, lossFunction, Y):\n",
    "        predY = self.historyA[(len(self.historyA)-1)]\n",
    "        return lossFunction(Y,self.predY)\n",
    "\n",
    "    def BackProp(self, a, h, dataPoint, dataLabel):\n",
    "        return Algorithms.BackProp(self.network, a, h, dataPoint, dataLabel)\n",
    "    \n",
    "    def fit(self, optimizer, batchSize, learningRate, activation, trainx, train_y, decay, epochs):\n",
    "        \n",
    "        #break data into training and validation\n",
    "        indices = np.arange(len(trainx))\n",
    "        np.random.shuffle(indices)\n",
    "        trainx = trainx[indices]\n",
    "        train_y = train_y[indices]\n",
    "        \n",
    "        valTest_x = trainx[int(0.9*len(trainx)):]\n",
    "        valTest_y = train_y[int(0.9*len(train_y)):]\n",
    "        \n",
    "        trainx = trainx[:int(0.9*len(trainx))]\n",
    "        train_y = train_y[:int(0.9*len(train_y))]\n",
    "        \n",
    "        if activation == \"relu\":\n",
    "            activate = Functions.reLU\n",
    "            derivative = Functions.derivative_reLU\n",
    "            output = Functions.softmax\n",
    "        elif activation == \"tanh\":\n",
    "            activate = Functions.tanh\n",
    "            derivative = Functions.derivative_tanh\n",
    "            output = Functions.softmax\n",
    "        elif activation == \"identity\":\n",
    "            activate = Functions.identity\n",
    "            derivative = Functions.derivative_identity\n",
    "            output = Functions.softmax\n",
    "        else:\n",
    "            activate = Functions.sigmoid\n",
    "            derivative = Functions.derivative_sigmoid\n",
    "            output = Functions.softmax\n",
    "        \n",
    "        #print(optimizer)\n",
    "        \n",
    "        if optimizer == \"momentum\":\n",
    "            self.weights, self.biases = Algorithms.miniBatchMGD(self.weights,self.biases , batchSize, learningRate, activate, output, derivative,  trainx, train_y, valTest_x, valTest_y, decay, epochs)\n",
    "        elif optimizer == \"nag\":\n",
    "            self.weights, self.biases = Algorithms.miniBatchNAG(self.weights,self.biases , batchSize, learningRate,activate, output, derivative , trainx, train_y, valTest_x, valTest_y, decay, epochs)\n",
    "        elif optimizer == \"rmsprop\":\n",
    "            self.weights, self.biases = Algorithms.RMSProp(self.weights,self.biases , batchSize, learningRate, activate, output, derivative,  trainx, train_y, valTest_x, valTest_y, decay, epochs)\n",
    "        elif optimizer == \"adam\":\n",
    "            self.weights, self.biases = Algorithms.ADAM(self.weights,self.biases , batchSize, learningRate,activate, output, derivative,  trainx, train_y, valTest_x, valTest_y, decay, epochs)\n",
    "        elif optimizer == \"nadam\":\n",
    "            self.weights, self.biases = Algorithms.NADAM(self.weights,self.biases , batchSize, learningRate, activate, output, derivative,  trainx, train_y, valTest_x, valTest_y, decay, epochs)\n",
    "        else:\n",
    "            self.weights, self.biases = Algorithms.miniBatchGD(self.weights,self.biases , batchSize, learningRate, activate, output, derivative , trainx, train_y, valTest_x, valTest_y, decay, epochs)\n",
    "        \n",
    "        return self.weights,self.biases\n",
    "            \n",
    "    def evaluateNetwork(self, testx, tes_ty):\n",
    "        Algorithms.evaluateNetwork(self.weights, self.biases, testx, test_y)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "Bu5XtsgmjyaH"
   },
   "outputs": [],
   "source": [
    "class Algorithms:\n",
    "    @staticmethod\n",
    "    def ForwardProp(weights, bias, activate, output, inputLayer):\n",
    "        L = len(weights)-1\n",
    "        a = []\n",
    "        h = []\n",
    "        a.append(np.matmul(weights[0],inputLayer)+bias[0])\n",
    "        h.append(activate(a[0]))\n",
    "        for k in range(1,L):\n",
    "            a.append(np.matmul(weights[k],h[k-1].T)+bias[k])\n",
    "            h.append(activate(a[k]))\n",
    "        a.append(np.matmul(weights[L],h[L-1].T)+bias[L])\n",
    "        h.append(output(a[L]))\n",
    "        return a,h\n",
    "    @staticmethod\n",
    "    def BackProp(weights, biases, a, h, derivative, dataPoint, dataLabel):\n",
    "        L = len(weights)-1\n",
    "        gradaL = -(Functions.onehot(dataLabel)-h[len(h)-1])\n",
    "        dw = np.zeros_like(weights)\n",
    "        db = np.zeros_like(biases)\n",
    "        for k in range(L,0,-1):\n",
    "            gradW = np.outer(gradaL, h[k-1].T)\n",
    "            gradB = gradaL\n",
    "            dw[k] = gradW\n",
    "            db[k] = gradB\n",
    "\n",
    "            gradhL_1 = np.matmul(np.transpose(weights[k]),gradaL)\n",
    "            gradaL_1 = np.multiply(gradhL_1, derivative(a[k-1]))\n",
    "            gradaL = gradaL_1\n",
    "        dw[0] = np.outer(gradaL,dataPoint.T)\n",
    "        db[0] = gradaL\n",
    "        return dw, db\n",
    "\n",
    "    @staticmethod\n",
    "    def miniBatchMGD(weights, biases, batchSize, learningRate, activate, output, derivative, dataPoints, dataLabels, valTest_x, valTest_y, decay, epochs):\n",
    "        lossTrack = []\n",
    "        validation = []\n",
    "        beta = 0.9\n",
    "        prevWeights = np.zeros_like(weights)\n",
    "        prevBiases = np.zeros_like(biases)\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            indices = np.arange(len(dataPoints))\n",
    "            np.random.shuffle(indices)\n",
    "            batchX = dataPoints[indices]\n",
    "            batchY = dataLabels[indices]\n",
    "            for i in range(math.floor(len(dataPoints)/batchSize)):\n",
    "                trainer = batchX[i*batchSize:i*batchSize+batchSize]\n",
    "                labeler = batchY[i*batchSize:i*batchSize+batchSize]\n",
    "                batchLoss = 0.0\n",
    "                dw = np.zeros_like(weights)\n",
    "                db = np.zeros_like(biases)\n",
    "                for data in range(batchSize):\n",
    "                    a,h = Algorithms.ForwardProp(weights, biases , activate, output, trainer[data])\n",
    "                    currWeights, currBiases = Algorithms.BackProp(weights, biases, a, h, derivative, trainer[data], labeler[data])\n",
    "                    batchLoss += Functions.crossEntropyLoss(Functions.onehot(labeler[data]), h[-1])\n",
    "                    dw += currWeights\n",
    "                    db += currBiases\n",
    "                batchLoss /= batchSize\n",
    "                dw /= batchSize\n",
    "                db /= batchSize\n",
    "                momentumWeights = prevWeights*beta + dw*1.0\n",
    "                momentumBiases = prevBiases*beta + db*1.0\n",
    "                weights -= learningRate*(momentumWeights + decay*weights)\n",
    "                biases -= learningRate*(momentumBiases + decay*biases)\n",
    "                prevWeights = momentumWeights\n",
    "                prevBiases = momentumBiases\n",
    "                lossTrack.append(batchLoss)\n",
    "            #wandb.log({'valAcc':(Algorithms.evaluateNetwork(weights, biases, valTest_x, valTest_y)), 'epoch':epoch})\n",
    "            validation.append(Algorithms.evaluateNetwork(weights, biases, valTest_x, valTest_y))\n",
    "            #print(\"The val_acc after this epoch is: \"+ str(validation))\n",
    "        Functions.plot(validation)\n",
    "        return weights, biases\n",
    "\n",
    "    @staticmethod\n",
    "    def ADAM(weights, biases, batchSize, learningRate, activate, output, derivative, dataPoints, dataLabels, valTest_x, valTest_y, decay, epochs):\n",
    "        validation = []\n",
    "        prev_val = 0.0\n",
    "        lossTrack = []\n",
    "        beta1 = 0.9\n",
    "        beta2 = 0.99\n",
    "        epsilon = 0.000001\n",
    "        m_w = np.zeros_like(weights)\n",
    "        v_w = np.zeros_like(weights)\n",
    "        m_b = np.zeros_like(biases)\n",
    "        v_b = np.zeros_like(biases)\n",
    "        learnerRateW = np.full_like(weights, learningRate)\n",
    "        learnerRateB = np.full_like(biases, learningRate)\n",
    "        i = 0\n",
    "        \n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            indices = np.arange(len(dataPoints))\n",
    "            np.random.shuffle(indices)\n",
    "            batchX = dataPoints[indices]\n",
    "            batchY = dataLabels[indices]\n",
    "            for i in range(math.floor(len(dataPoints)/batchSize)):\n",
    "                trainer = batchX[i*batchSize:i*batchSize+batchSize]\n",
    "                labeler = batchY[i*batchSize:i*batchSize+batchSize]\n",
    "                batchLoss = 0.0\n",
    "                dw = np.zeros_like(weights)\n",
    "                db = np.zeros_like(biases)\n",
    "                for data in range(batchSize):\n",
    "                    a,h = Algorithms.ForwardProp(weights, biases,activate, output, trainer[data])\n",
    "                    currWeights, currBiases = Algorithms.BackProp(weights, biases , a, h, derivative, trainer[data], labeler[data])\n",
    "                    batchLoss += Functions.crossEntropyLoss(Functions.onehot(labeler[data]), h[-1])\n",
    "                    if abs(batchLoss) == float(\"inf\"):\n",
    "                        continue\n",
    "                    dw += currWeights\n",
    "                    db += currBiases\n",
    "                batchLoss /= batchSize\n",
    "                dw /= batchSize\n",
    "                db /= batchSize\n",
    "                m_w = beta1*m_w + (1-beta1)*dw\n",
    "                m_b = beta1*m_b + (1-beta1)*db\n",
    "                v_w = v_w*beta2 + (1-beta2)*dw**2\n",
    "                v_b = v_b*beta2 + (1-beta2)*db**2\n",
    "                \n",
    "                m_w_hat = m_w/(1 - np.power(beta1, i+1))\n",
    "                m_b_hat = m_b/(1 - np.power(beta1, i+1))\n",
    "                v_w_hat = v_w/(1 - np.power(beta2, i+1))\n",
    "                v_b_hat = v_b/(1 - np.power(beta2, i+1))\n",
    "                \n",
    "                i+=1\n",
    "                \n",
    "                tempW = np.zeros_like(m_w)\n",
    "                tempB = np.zeros_like(m_b)\n",
    "                for i in range(len(dw)):\n",
    "                    tempW[i] = np.sqrt(v_w_hat[i])\n",
    "                    tempB[i] = np.sqrt(v_b_hat[i])\n",
    "                weights = weights - ((learnerRateW*(dw + decay*weights))/(tempW + epsilon))\n",
    "                biases = biases - (learnerRateB*(db + decay*biases))/(tempB+epsilon)\n",
    "                lossTrack.append(batchLoss)\n",
    "            #wandb.log({'valAcc':(Algorithms.evaluateNetwork(weights, biases, valTest_x, valTest_y)), 'epoch':epoch})\n",
    "            validation.append(Algorithms.evaluateNetwork(weights, biases, valTest_x, valTest_y))\n",
    "            if validation[-1] <= prev_val:\n",
    "                patience -= 1\n",
    "            else:\n",
    "                patience = 3\n",
    "                prev_weights = weights\n",
    "                prev_biases = biases\n",
    "            \n",
    "            if patience == 0:\n",
    "                return prev_weights, prev_biases\n",
    "            #print(\"The val_acc after this epoch is: \"+ str(validation))\n",
    "        Functions.plot(validation)\n",
    "            #print(\"The loss after this epoch is: \"+ str(batchLoss))\n",
    "        return weights,biases\n",
    "\n",
    "    @staticmethod\n",
    "    def NADAM(weights, biases, batchSize, learningRate, activate, output, derivative, dataPoints, dataLabels, valTest_x, valTest_y, decay, epochs):\n",
    "        patience = 3\n",
    "        lossTrack = []\n",
    "        validation = []\n",
    "        prev_val = 0.0\n",
    "        prevWeights = np.zeros_like(weights)\n",
    "        prevBiases = np.zeros_like(biases)\n",
    "        beta1 = 0.9\n",
    "        beta2 = 0.99\n",
    "        epsilon = 0.000001\n",
    "        prev_weights = np.zeros_like(weights)\n",
    "        prev_biases = np.zeros_like(biases)\n",
    "        m_w = np.zeros_like(weights)\n",
    "        v_w = np.zeros_like(weights)\n",
    "        m_b = np.zeros_like(biases)\n",
    "        v_b = np.zeros_like(biases)\n",
    "        learnerRateW = np.full_like(weights, learningRate)\n",
    "        learnerRateB = np.full_like(biases, learningRate)\n",
    "        i = 0\n",
    "        \n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            indices = np.arange(len(dataPoints))\n",
    "            np.random.shuffle(indices)\n",
    "            batchX = dataPoints[indices]\n",
    "            batchY = dataLabels[indices]\n",
    "            for i in range(math.floor(len(dataPoints)/batchSize)):\n",
    "                trainer = batchX[i*batchSize:i*batchSize+batchSize]\n",
    "                labeler = batchY[i*batchSize:i*batchSize+batchSize]\n",
    "                batchLoss = 0.0\n",
    "                dw = np.zeros_like(weights)\n",
    "                db = np.zeros_like(biases)\n",
    "                for data in range(batchSize):\n",
    "                    a,h = Algorithms.ForwardProp(weights - v_w*(beta1), biases - v_b*(beta1), activate, output, trainer[data])\n",
    "                    currWeights, currBiases = Algorithms.BackProp(weights - v_w*(beta1), biases - v_b*(beta1), a, h, derivative, trainer[data], labeler[data])\n",
    "                    batchLoss += Functions.crossEntropyLoss(Functions.onehot(labeler[data]), h[-1])\n",
    "                    if batchLoss.isnan():\n",
    "                        continue\n",
    "                    dw += currWeights\n",
    "                    db += currBiases\n",
    "                batchLoss /= batchSize\n",
    "                dw /= batchSize\n",
    "                db /= batchSize\n",
    "                m_w = beta1*m_w + (1-beta1)*dw\n",
    "                m_b = beta1*m_b + (1-beta1)*db\n",
    "                v_w = v_w*beta2 + (1-beta2)*dw**2\n",
    "                v_b = v_b*beta2 + (1-beta2)*db**2\n",
    "                \n",
    "                m_w_hat = m_w/(1 - np.power(beta1, i+1))\n",
    "                m_b_hat = m_b/(1 - np.power(beta1, i+1))\n",
    "                v_w_hat = v_w/(1 - np.power(beta2, i+1))\n",
    "                v_b_hat = v_b/(1 - np.power(beta2, i+1))\n",
    "                \n",
    "                i+=1\n",
    "                \n",
    "                tempW = np.zeros_like(m_w)\n",
    "                tempB = np.zeros_like(m_b)\n",
    "                for j in range(len(dw)):\n",
    "                    tempW[j] = np.sqrt(v_w_hat[j])\n",
    "                    tempB[j] = np.sqrt(v_b_hat[j])\n",
    "                weights = weights - ((learnerRateW*(dw + decay*weights))/(tempW + epsilon))\n",
    "                biases = biases - (learnerRateB*(db + decay*biases))/(tempB+epsilon)\n",
    "                lossTrack.append(batchLoss)\n",
    "            #wandb.log({'valAcc':(Algorithms.evaluateNetwork(weights, biases, valTest_x, valTest_y)), 'epoch':epoch})\n",
    "            validation.append(Algorithms.evaluateNetwork(weights, biases, valTest_x, valTest_y))\n",
    "            if validation[-1] <= prev_val:\n",
    "                patience -= 1\n",
    "            else:\n",
    "                patience = 3\n",
    "                prev_weights = weights\n",
    "                prev_biases = biases\n",
    "            \n",
    "            if patience == 0:\n",
    "                return prev_weights, prev_biases\n",
    "            #print(\"The val_acc after this epoch is: \"+ str(validation))\n",
    "        Functions.plot(validation)\n",
    "            #print(\"The loss after this epoch is: \"+ str(batchLoss))\n",
    "        return prev_weights, prev_biases\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def miniBatchNAG(weights, biases, batchSize, learningRate, activate, output, derivative, dataPoints, dataLabels, valTest_x, valTest_y, decay, epochs):\n",
    "        lossTrack = []\n",
    "        validation = []\n",
    "        beta = 0.9\n",
    "        prevWeights = np.zeros_like(weights)\n",
    "        prevBiases = np.zeros_like(biases)\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            indices = np.arange(len(dataPoints))\n",
    "            np.random.shuffle(indices)\n",
    "            batchX = dataPoints[indices]\n",
    "            batchY = dataLabels[indices]\n",
    "            for i in range(math.floor(len(dataPoints)/batchSize)):\n",
    "                trainer = batchX[i*batchSize:i*batchSize+batchSize]\n",
    "                labeler = batchY[i*batchSize:i*batchSize+batchSize]\n",
    "                batchLoss = 0.0\n",
    "                tempWeights = np.zeros_like(weights)\n",
    "                tempBiases = np.zeros_like(biases)\n",
    "                for data in range(batchSize):\n",
    "                    a,h = Algorithms.ForwardProp(weights-prevWeights, biases-prevBiases, activate, output, trainer[data])\n",
    "                    currWeights, currBiases = Algorithms.BackProp(weights-prevWeights, biases-prevBiases, a, h, derivative, trainer[data], labeler[data])\n",
    "                    batchLoss += Functions.crossEntropyLoss(Functions.onehot(labeler[data]), h[-1])\n",
    "                    tempWeights += currWeights\n",
    "                    tempBiases += currBiases\n",
    "                batchLoss /= batchSize\n",
    "                tempWeights /= batchSize\n",
    "                tempBiases /= batchSize\n",
    "                momentumWeights = beta*prevWeights + tempWeights*1.0\n",
    "                momentumBiases = beta*prevBiases + tempBiases*1.0\n",
    "                weights = weights - learningRate*(momentumWeights + decay*weights) \n",
    "                biases = biases - learningRate*(momentumBiases + decay*biases)\n",
    "                prevWeights = momentumWeights\n",
    "                prevBiases = momentumBiases\n",
    "                lossTrack.append(batchLoss)\n",
    "            wandb.log({'valAcc':(Algorithms.evaluateNetwork(weights, biases, valTest_x, valTest_y)), 'epoch':epoch})\n",
    "            validation.append(Algorithms.evaluateNetwork(weights, biases, valTest_x, valTest_y))\n",
    "            #print(\"The val_acc after this epoch is: \"+ str(validation))\n",
    "            Functions.plot(validation)\n",
    "            #print(\"The loss after this epoch is: \"+ str(batchLoss))\n",
    "            Functions.plot(lossTrack)\n",
    "        return net\n",
    "    \n",
    "    @staticmethod\n",
    "    def RMSProp(weights, biases, batchSize, learningRate, activate, output, derivative, dataPoints, dataLabels, valTest_x, valTest_y, decay, epochs):\n",
    "        lossTrack = []\n",
    "        validation = []\n",
    "        beta = 0.5\n",
    "        epsilon = 0.000001\n",
    "        momentumWeights = np.zeros_like(weights)\n",
    "        momentumBiases = np.zeros_like(biases)\n",
    "        learnerRateW = np.full_like(weights, learningRate)\n",
    "        learnerRateB = np.full_like(biases, learningRate)\n",
    "        \n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            indices = np.arange(len(dataPoints))\n",
    "            np.random.shuffle(indices)\n",
    "            batchX = dataPoints[indices]\n",
    "            batchY = dataLabels[indices]\n",
    "            for i in range(math.floor(len(dataPoints)/batchSize)):\n",
    "                trainer = batchX[i*batchSize:i*batchSize+batchSize]\n",
    "                labeler = batchY[i*batchSize:i*batchSize+batchSize]\n",
    "                batchLoss = 0.0\n",
    "                dw = np.zeros_like(weights)\n",
    "                db = np.zeros_like(biases)\n",
    "                for data in range(batchSize):\n",
    "                    a,h = Algorithms.ForwardProp(weights, biases, activate, output, trainer[data])\n",
    "                    currWeights, currBiases = Algorithms.BackProp(weights, biases , a, h, derivative, trainer[data], labeler[data])\n",
    "                    batchLoss += Functions.crossEntropyLoss(Functions.onehot(labeler[data]), h[-1])\n",
    "                    dw += currWeights\n",
    "                    db += currBiases\n",
    "                batchLoss /= batchSize\n",
    "                dw /= batchSize\n",
    "                db /= batchSize\n",
    "                momentumWeights = momentumWeights*beta + (1-beta)*dw**2\n",
    "                momentumBiases = momentumBiases*beta + (1-beta)*db**2\n",
    "                tempW = np.zeros_like(momentumWeights)\n",
    "                tempB = np.zeros_like(momentumBiases)\n",
    "                for i in range(len(dw)):\n",
    "                    tempW[i] = np.sqrt(momentumWeights[i])\n",
    "                    tempB[i] = np.sqrt(momentumBiases[i])\n",
    "                weights = weights - ((learnerRateW)*(dw + decay*weights)/(tempW + epsilon))\n",
    "                biases = biases - (learnerRateB*(db + decay*biases))/(tempB+epsilon)\n",
    "                lossTrack.append(batchLoss)\n",
    "            wandb.log({'valAcc':(Algorithms.evaluateNetwork(weights, biases, valTest_x, valTest_y)), 'epoch':epoch})\n",
    "            validation.append(Algorithms.evaluateNetwork(weights, biases, valTest_x, valTest_y))\n",
    "            #print(\"The val_acc after this epoch is: \"+ str(validation))\n",
    "            Functions.plot(validation)\n",
    "            #print(\"The loss after this epoch is: \"+ str(batchLoss))\n",
    "        return weights, biases\n",
    "\n",
    "    @staticmethod\n",
    "    def miniBatchGD(weights, biases, batchSize, learningRate, activate, output, derivative, dataPoints, dataLabels, valTest_x, valTest_y, decay, epochs):\n",
    "        validation = []\n",
    "        lossTrack = []\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            indices = np.arange(len(dataPoints))\n",
    "            np.random.shuffle(indices)\n",
    "            batchX = dataPoints[indices]\n",
    "            batchY = dataLabels[indices]\n",
    "            for i in range(math.floor(len(dataPoints)/batchSize)):\n",
    "                trainer = batchX[i*batchSize:i*batchSize+batchSize]\n",
    "                labeler = batchY[i*batchSize:i*batchSize+batchSize]\n",
    "                batchLoss = 0.0\n",
    "                dw = np.zeros_like(weights)\n",
    "                db = np.zeros_like(biases)\n",
    "                for data in range(batchSize):\n",
    "                    a,h = Algorithms.ForwardProp(weights, biases , activate, output, trainer[data])\n",
    "                    tempw,tempb = Algorithms.BackProp(weights, biases, a, h, derivative, trainer[data], labeler[data])\n",
    "                    dw+=tempw\n",
    "                    db+=tempb\n",
    "                    batchLoss += Functions.crossEntropyLoss(Functions.onehot(labeler[data]), h[-1])\n",
    "                batchLoss /= batchSize\n",
    "                dw /= batchSize\n",
    "                db /= batchSize\n",
    "                weights -= learningRate*(dw + decay*weights)\n",
    "                biases -= learningRate*(db + decay*biases)\n",
    "                lossTrack.append(batchLoss)\n",
    "            print(\"The loss after this epoch is: \"+ str(batchLoss))\n",
    "            wandb.log({'valAcc':(Algorithms.evaluateNetwork(weights, biases, valTest_x, valTest_y)), 'epoch':epoch})\n",
    "            validation.append(Algorithms.evaluateNetwork(weights, biases, valTest_x, valTest_y))\n",
    "            #print(\"The val_acc after this epoch is: \"+ str(validation))\n",
    "            Functions.plot(validation)\n",
    "        return weights, biases\n",
    "    \n",
    "    @staticmethod\n",
    "    def evaluateNetwork(weights, biases,test_x, test_y):\n",
    "        num_acc = 0\n",
    "        for i in range(len(test_x)):\n",
    "            a,h = Algorithms.ForwardProp(weights, biases, Functions.sigmoid, Functions.softmax, test_x[i])\n",
    "            h = np.array(h, dtype = object)\n",
    "            predY =   np.argmax(h[len(h)-1])\n",
    "            if test_y[i] == predY:\n",
    "                num_acc+=1\n",
    "        return (num_acc/len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = trainx[:int(0.9*len(trainx))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "valTest = trainx[int(0.9*len(trainx)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "R-YOAwnCmO3I",
    "outputId": "a052aca6-18cc-4d10-a3d6-17257b72ab4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cC3J4fScHacM"
   },
   "outputs": [],
   "source": [
    "a,h = Algorithms.ForwardProp(net, Functions.sigmoid, Functions.softmax, train_x[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L1KBO1xmaxu8",
    "outputId": "aa351438-35e1-4e7e-99c3-1a86fae078b7"
   },
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "id": "-DhPxwMbl6qX",
    "outputId": "5f0b4ef2-96a9-4a5b-f724-c8a1d521325e"
   },
   "outputs": [],
   "source": [
    "\n",
    "batchSize = 32\n",
    "gradient = np.zeros_like(net)\n",
    "lossTrack = []\n",
    "for epoch in tqdm(range(15)):\n",
    "    indices = np.arange(len(trainx))\n",
    "    np.random.shuffle(indices)\n",
    "    batchX = trainx[indices]\n",
    "    batchY = train_y[indices]\n",
    "    for i in range(math.ceil(len(trainx)/batchSize)):\n",
    "        trainer = batchX[i*batchSize:i*batchSize+batchSize]\n",
    "        labeler = batchY[i*batchSize:i*batchSize+batchSize]\n",
    "        batchLoss = 0.0\n",
    "        for data in range(batchSize):\n",
    "            a,h = Algorithms.ForwardProp(net, Functions.sigmoid, Functions.softmax, trainer[data])\n",
    "            currGrad = Algorithms.BackProp(net, a, h, trainer[data], labeler[data])\n",
    "            batchLoss += Functions.crossEntropyLoss(Functions.onehot(labeler[data]), h[-1])\n",
    "            gradient += currGrad\n",
    "        batchLoss /= 32\n",
    "        gradient /= 32\n",
    "        net = net - 0.01*gradient \n",
    "        lossTrack.append(batchLoss)\n",
    "    print(\"The loss after this epoch is: \"+ str(batchLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-hhR7Gex1BK9",
    "outputId": "57a17ae8-adef-4561-8bbb-a0206fa23106"
   },
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uckwQu3vbr9b"
   },
   "outputs": [],
   "source": [
    "gradient = neuralNet.BackProp(a,h,train_x[1], train_y[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trXRsTlNb0_1"
   },
   "outputs": [],
   "source": [
    "net = net - gradient*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SeXnBQQMbw_U",
    "outputId": "efc6c2b2-af74-4a82-f9e9-3c23fd302cd6"
   },
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CvzSP-M4btcN",
    "outputId": "001904ed-f2ec-4f76-b167-2678d1f33835"
   },
   "outputs": [],
   "source": [
    "np.argmax(np.array(h[L]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RcwywNK0blOr",
    "outputId": "d764dc8a-d727-443b-cb91-ba121fe78f26"
   },
   "outputs": [],
   "source": [
    "while np.argmax(np.array(h[L])):\n",
    "    for i in range(10):\n",
    "        a,h = Algorithms.ForwardProp(net,Functions.sigmoid, Functions.softmax, train_x[4])\n",
    "        gradient = neuralNet.BackProp(a,h,train_x[4], train_y[4])\n",
    "        net = net - 0.1*gradient\n",
    "        print(np.argmax(np.array(h[L])), end = \", \"),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-df0oArs006R",
    "outputId": "4218ed61-af21-4c62-cdac-3b2ec63efbe8"
   },
   "outputs": [],
   "source": [
    "train_y[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V0eqMHkIz3to",
    "outputId": "4a35e5fc-75b2-4bb2-de9a-8d103c5bb6c9"
   },
   "outputs": [],
   "source": [
    "num_acc = 0\n",
    "for i in range(len(test_x)):\n",
    "    a,h = Algorithms.ForwardProp(net, Functions.sigmoid, Functions.softmax, test_x[i])\n",
    "    h = np.array(h)\n",
    "    predY =   np.argmax(h[len(h)-1])\n",
    "    print(predY)\n",
    "    if test_y[i] == predY:\n",
    "        num_acc+=1\n",
    "print(num_acc/len(test_y), end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o84TF_u3yVv9",
    "outputId": "074c498e-5519-4f15-dc86-049be1c6382a"
   },
   "outputs": [],
   "source": [
    "len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TUcuGN-SzSyq",
    "outputId": "f6614617-7859-48d3-dff7-623f7622625c"
   },
   "outputs": [],
   "source": [
    "gradient[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OY0Zy9psDtk7"
   },
   "outputs": [],
   "source": [
    "for i in gradient[0]:\n",
    "    print(i, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I3YdLFqZU8Ci",
    "outputId": "52462d9f-b600-46f9-9403-a93bdb09c341"
   },
   "outputs": [],
   "source": [
    "gradient[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPDcvGye0lF7"
   },
   "outputs": [],
   "source": [
    "gradaL = -(Functions.onehot(train_y[1])-h[len(h)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PcCtxLxzFKVG"
   },
   "outputs": [],
   "source": [
    "gradhL_1 = np.matmul(np.transpose(net[(len(net)-1)]),aL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9xEUE6XKesg"
   },
   "outputs": [],
   "source": [
    "gradaL_1 = np.multiply(net[len(net)-1][:,:len(net[len(net)-1][0])-1], Functions.derivative_sigmoid(a[len(net)-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K72jzJOiJSR3"
   },
   "outputs": [],
   "source": [
    "gradW = np.outer(gradaL,h[len(net)-2].T)\n",
    "gradB = gradaL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XDbZT58hUOWW"
   },
   "outputs": [],
   "source": [
    "gradB.resize((len(gradB),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3-e7uWUUYd_",
    "outputId": "2dccdc5f-1f4f-4de9-ef20-bdc5f9e31910"
   },
   "outputs": [],
   "source": [
    "gradB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WdZHmwrRR2rx",
    "outputId": "df26a5dc-df87-4147-c06a-0d3df7c1d70d"
   },
   "outputs": [],
   "source": [
    "np.append(gradW,gradB.resize((10,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RDIXmbKHNo25",
    "outputId": "6d44560f-8280-4146-b7bd-dedf9486be76"
   },
   "outputs": [],
   "source": [
    "gradaL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d7_71o1X06hg",
    "outputId": "5899546a-1304-47a4-e96b-f0f8edbce0ee"
   },
   "outputs": [],
   "source": [
    "a[len(net)-2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k65CaJIefUTY"
   },
   "outputs": [],
   "source": [
    "weights = net[0][:,:len(net[0][0])-1]\n",
    "bias = net[0][:,len(net[0][0])-1]\n",
    "temp = np.matmul(weights,train_x[0])+bias\n",
    "temp = temp/np.linalg.norm(temp)\n",
    "a = []\n",
    "a.append(temp)\n",
    "h = []\n",
    "h.append(Functions.sigmoid(a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZafDhQ7LmcUx"
   },
   "outputs": [],
   "source": [
    "weights = net[L][:,:len(net[L][0])-1]\n",
    "bias = net[L][:,len(net[L][0])-1]\n",
    "temp = np.matmul(weights,h[0])+bias\n",
    "temp = temp/np.linalg.norm(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "epu4dvEji2mG"
   },
   "outputs": [],
   "source": [
    "L = len(net)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tg0dnhLfheDu",
    "outputId": "93e6fdc7-9cf7-4236-b55e-550c4459f101"
   },
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qohv21-jxL88"
   },
   "outputs": [],
   "source": [
    "#The class of FeedForwardNeuralNetwor\n",
    "\n",
    "class FFNet:\n",
    "    #constructor\n",
    "    hidden = []\n",
    "    input = []\n",
    "    output = []\n",
    "    def __init__(self,number_of_hidden_layers, number_of_inputs, number_of_outputs):\n",
    "        self.number_of_inputs = number_of_inputs\n",
    "        self.number_of_hidden_layers = number_of_hidden_layers\n",
    "        self.number_of_outputs = number_of_outputs\n",
    "        #At the same time, the layers input layers mus also be initialized.\n",
    "\n",
    "        input = [0 for i in range(number_of_inputs)]\n",
    "        output = [0 for i in range(number_of_outputs)]\n",
    "        hidden = [[]]\n",
    "\n",
    "        #input and output layers are nothing but simple lists\n",
    "    \n",
    "    #Method for creating layers\n",
    "    def add_hidden_layer(number_of_neurons):\n",
    "        temp_weights = [0 for i in range(number_of_neurons+1)] #The +1 is for bias values\n",
    "        hidden.append(temp_weights)\n",
    "    \n",
    "    def backward_propagate(a,h, pred_y):\n",
    "        delthet[L] = -(exp(y) - pred_y) #with respect to output layer\n",
    "        for k in range(0,L-1,-1):\n",
    "            delthetw = np.matmul(delthet[k], h[k-1].T)\n",
    "            delthetb = delthet[k]\n",
    "            deltheth = np.matmul(weights[k].T, delthet[k])\n",
    "            delthet[k-1] = hadamard(deltheth, preac(a)) \n",
    "\n",
    "    def forward_propagate():\n",
    "        #here, we are calculating the preactivations and activations.\n",
    "        #we then store them in an array and return it.\n",
    "        \n",
    "        for k in range(number_of_levels-1):\n",
    "            a[k] = biases[k] + np.matmul(weights[k], h[k-1])\n",
    "            h[k] = g(a[k])\n",
    "        a[number_of_levels-1] = biases[number_of_levels] + np.matmul(weights[number_of_levels],h[number_of_levels-1])\n",
    "        pred_y = output(a[number_of_levels-1])\n",
    "        return a,h, pred_y\n",
    "\n",
    "\n",
    "    def gradient_descent():\n",
    "        a,h, pred_y = forward_propagate()\n",
    "        delthet = backward_propagate(a,h, pred_y)\n",
    "        thet += delthet\n",
    "\n",
    "    def fit(dataset):\n",
    "        for x,y in dataset:\n",
    "            loss = forward(x,y)\n",
    "            delthet = backward(loss)\n",
    "            thet += learn_rate*delthet\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
